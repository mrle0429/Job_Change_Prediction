{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a81d8f",
   "metadata": {},
   "source": [
    "# Data Science Job Change Prediction\n",
    "- Author: Le Liu\n",
    "- Course: COMP3010J Machine Learning\n",
    "\n",
    "\n",
    "## 1. Project Overview\n",
    "\n",
    "This project aims to predict whether a candidate is looking for a job change based on various demographic and professional features. Then infer the key factors influencing their decision.\n",
    "\n",
    "**Dataset:** `data-science-job-change.csv`\n",
    "\n",
    "**Problem Type:** Binary Classification\n",
    "\n",
    "**Target Variable:** `target` (1.0 = Looking for job change, 0.0 = Not looking for job change)\n",
    "\n",
    "\n",
    "\n",
    "*Project Structure*\n",
    "\n",
    "1. **Introduction** - Project overview and objectives\n",
    "2. **Load and Analyse Data** - Data loading and initial exploration\n",
    "3. **Data Cleaning** - Handle missing values and data quality issues\n",
    "4. **Data Visualisation** - Exploratory data analysis with plots\n",
    "5. **Attribute Selection** - Feature selection and engineering\n",
    "6. **Model Selection and Experiments** - Train and compare models\n",
    "7. **Final Model Training** - Train the best model\n",
    "8. **Further Analysis and Discussion** - Model interpretation\n",
    "9. **Discussion** - Conclusions and future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6ec4c",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "bc80cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (19158, 14)\n",
      "Number of rows: 19158\n",
      "Number of columns: 14\n",
      "\n",
      "First 5 rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>gender</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8949</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29725</td>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>Male</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11561</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>STEM</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33241</td>\n",
       "      <td>city_115</td>\n",
       "      <td>0.789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No relevent experience</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Business Degree</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>never</td>\n",
       "      <td>52</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666</td>\n",
       "      <td>city_162</td>\n",
       "      <td>0.767</td>\n",
       "      <td>Male</td>\n",
       "      <td>Has relevent experience</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>Masters</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Funded Startup</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enrollee_id      city  city_development_index gender  \\\n",
       "0         8949  city_103                   0.920   Male   \n",
       "1        29725   city_40                   0.776   Male   \n",
       "2        11561   city_21                   0.624    NaN   \n",
       "3        33241  city_115                   0.789    NaN   \n",
       "4          666  city_162                   0.767   Male   \n",
       "\n",
       "       relevent_experience enrolled_university education_level  \\\n",
       "0  Has relevent experience       no_enrollment        Graduate   \n",
       "1   No relevent experience       no_enrollment        Graduate   \n",
       "2   No relevent experience    Full time course        Graduate   \n",
       "3   No relevent experience                 NaN        Graduate   \n",
       "4  Has relevent experience       no_enrollment         Masters   \n",
       "\n",
       "  major_discipline experience company_size    company_type last_new_job  \\\n",
       "0             STEM        >20          NaN             NaN            1   \n",
       "1             STEM         15        50-99         Pvt Ltd           >4   \n",
       "2             STEM          5          NaN             NaN        never   \n",
       "3  Business Degree         <1          NaN         Pvt Ltd        never   \n",
       "4             STEM        >20        50-99  Funded Startup            4   \n",
       "\n",
       "   training_hours  target  \n",
       "0              36     1.0  \n",
       "1              47     0.0  \n",
       "2              83     0.0  \n",
       "3              52     1.0  \n",
       "4               8     0.0  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('data-science-job-change.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "405bd547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Summary:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19158.000000</td>\n",
       "      <td>19158.000000</td>\n",
       "      <td>19158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.828848</td>\n",
       "      <td>65.366896</td>\n",
       "      <td>0.249348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.123362</td>\n",
       "      <td>60.058462</td>\n",
       "      <td>0.432647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.448000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.903000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.949000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_development_index  training_hours        target\n",
       "count            19158.000000    19158.000000  19158.000000\n",
       "mean                 0.828848       65.366896      0.249348\n",
       "std                  0.123362       60.058462      0.432647\n",
       "min                  0.448000        1.000000      0.000000\n",
       "25%                  0.740000       23.000000      0.000000\n",
       "50%                  0.903000       47.000000      0.000000\n",
       "75%                  0.920000       88.000000      0.000000\n",
       "max                  0.949000      336.000000      1.000000"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"=\"*60)\n",
    "numerical_cols = ['city_development_index', 'training_hours', 'target']\n",
    "df[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2d50b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Health Report:\n",
      "================================================================================\n",
      "                Column  Missing_Count  Missing_Percentage Data_Type  Unique_Values\n",
      "           enrollee_id              0               0.000     int64          19158\n",
      "                  city              0               0.000    object            123\n",
      "city_development_index              0               0.000   float64             93\n",
      "                gender           4508              23.531    object              3\n",
      "   relevent_experience              0               0.000    object              2\n",
      "   enrolled_university            386               2.015    object              3\n",
      "       education_level            460               2.401    object              5\n",
      "      major_discipline           2813              14.683    object              6\n",
      "            experience             65               0.339    object             22\n",
      "          company_size           5938              30.995    object              8\n",
      "          company_type           6140              32.049    object              6\n",
      "          last_new_job            423               2.208    object              6\n",
      "        training_hours              0               0.000     int64            241\n",
      "                target              0               0.000   float64              2\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(3),\n",
    "    'Data_Type': df.dtypes,\n",
    "    'Unique_Values': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "\n",
    "print(\"Data Health Report:\")\n",
    "print(\"=\"*80)\n",
    "print(missing_data.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8fc5a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  3. Data Cleaning & Feature Engineering Strategy\n",
    "\n",
    "Based on the comprehensive data analysis above, here is the detailed processing strategy for each of the 14 features:\n",
    "\n",
    "###  Strategy Overview Table\n",
    "\n",
    "| # | Feature | Type | Action | Priority | Reason |\n",
    "|---|---------|------|--------|----------|--------|\n",
    "| 1 | `enrollee_id` | ID | **DELETE** | üî¥ High | No predictive value - just an identifier |\n",
    "| 2 | `city` | Categorical (123 values) | **Target Encoding** | üü° Medium | Too many categories for One-Hot |\n",
    "| 3 | `city_development_index` | Numerical | **Keep as-is** | üü¢ Low | Already numeric, no missing values |\n",
    "| 4 | `gender` | Categorical (3 values) | **Fill Missing + One-Hot** | üü° Medium | 23% missing, create \"Unknown\" category |\n",
    "| 5 | `relevent_experience` | Binary | **Label Encoding** | üü¢ Low | No missing, convert to 0/1 |\n",
    "| 6 | `enrolled_university` | Categorical (3 values) | **Fill Missing + One-Hot** | üü¢ Low | 2% missing, 3 clear categories |\n",
    "| 7 | `education_level` | Ordinal (5 values) | **Ordinal Encoding** | üü° Medium | 2% missing, has natural order |\n",
    "| 8 | `major_discipline` | Categorical (6 values) | **Fill Missing + One-Hot** | üü° Medium | 15% missing, may correlate with education |\n",
    "| 9 | `experience` | Ordinal (22 values) | **Ordinal Encoding** | üî¥ High | Convert to numeric years (e.g., \"<1\"‚Üí0, \">20\"‚Üí21) |\n",
    "| 10 | `company_size` | Ordinal (8 values) | **Fix Format + Ordinal** | üî¥ High | 31% missing, FIX \"10/49\" ‚Üí \"10-49\" |\n",
    "| 11 | `company_type` | Categorical (6 values) | **Fill Missing + One-Hot** | üü° Medium | 32% missing, create \"Unknown\" |\n",
    "| 12 | `last_new_job` | Ordinal (6 values) | **Ordinal Encoding** | üü¢ Low | 2% missing, convert to numeric |\n",
    "| 13 | `training_hours` | Numerical | **Keep as-is** | üü¢ Low | Already numeric, no missing values |\n",
    "| 14 | `target` | Binary | **Keep as-is** | N/A | Target variable - no transformation needed |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6ee55",
   "metadata": {},
   "source": [
    "### Data Cleaning Implementation Plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "68762c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (19158, 14)\n",
      "Starting data cleaning process...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the original dataframe for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(f\"Original dataset shape: {df_clean.shape}\")\n",
    "print(f\"Starting data cleaning process...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c8b8ce92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 processed: enrollee_id\n",
      "Action: Deleted\n",
      "New shape: (19158, 13)\n",
      "Columns remaining: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 1: enrollee_id\n",
    "df_clean = df_clean.drop('enrollee_id', axis=1)\n",
    "\n",
    "print(\"Feature 1 processed: enrollee_id\")\n",
    "print(f\"Action: Deleted\")\n",
    "print(f\"New shape: {df_clean.shape}\")\n",
    "print(f\"Columns remaining: {df_clean.shape[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ea25fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 2: company_size\n",
      "======================================================================\n",
      "\n",
      "Step 1: Fix formatting error '10/49' ‚Üí '10-49'\n",
      "Fixed: '10/49' no longer present\n",
      "\n",
      "Step 2: Fill missing values with 'Unknown'\n",
      "   Missing before: 5938 (30.99%)\n",
      "   Missing after: 0\n",
      "\n",
      "Step 3: Ordinal encoding (small ‚Üí large)\n",
      "   Encoding mapping:\n",
      "      <10          ‚Üí 0  (1,308 samples)\n",
      "      10-49        ‚Üí 1  (1,471 samples)\n",
      "      50-99        ‚Üí 2  (3,083 samples)\n",
      "      100-500      ‚Üí 3  (2,571 samples)\n",
      "      500-999      ‚Üí 4  (877 samples)\n",
      "      1000-4999    ‚Üí 5  (1,328 samples)\n",
      "      5000-9999    ‚Üí 6  (563 samples)\n",
      "      10000+       ‚Üí 7  (2,019 samples)\n",
      "      Unknown      ‚Üí -1  (5,938 samples)\n",
      "\n",
      " Feature 2 processed: company_size\n",
      "   Type: int64\n",
      "   Range: -1 to 7\n",
      "   Missing: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 2: company_size\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 2: company_size\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Fix formatting error\n",
    "print(\"\\nStep 1: Fix formatting error '10/49' ‚Üí '10-49'\")\n",
    "before_fix = df_clean['company_size'].value_counts(dropna=False)\n",
    "df_clean['company_size'] = df_clean['company_size'].replace('10/49', '10-49')\n",
    "after_fix = df_clean['company_size'].value_counts(dropna=False)\n",
    "print(f\"Fixed: '10/49' no longer present\")\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "print(\"\\nStep 2: Fill missing values with 'Unknown'\")\n",
    "missing_count = df_clean['company_size'].isna().sum()\n",
    "print(f\"   Missing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "df_clean['company_size'] = df_clean['company_size'].fillna('Unknown')\n",
    "print(f\"   Missing after: {df_clean['company_size'].isna().sum()}\")\n",
    "\n",
    "# Step 3: Ordinal encoding\n",
    "print(\"\\nStep 3: Ordinal encoding (small ‚Üí large)\")\n",
    "size_order = {\n",
    "    '<10': 0,          # ÊúÄÂ∞è\n",
    "    '10-49': 1,\n",
    "    '50-99': 2,\n",
    "    '100-500': 3,\n",
    "    '500-999': 4,\n",
    "    '1000-4999': 5,\n",
    "    '5000-9999': 6,\n",
    "    '10000+': 7,       # ÊúÄÂ§ß\n",
    "    'Unknown': -1      # ‚Üê ÁâπÊÆäÂÄº,‰∏çÂú®È°∫Â∫è‰∏≠\n",
    "}\n",
    "df_clean['company_size'] = df_clean['company_size'].map(size_order)\n",
    "\n",
    "print(\"   Encoding mapping:\")\n",
    "for key, value in size_order.items():\n",
    "    count = (df_clean['company_size'] == value).sum()\n",
    "    print(f\"      {key:12s} ‚Üí {value}  ({count:,} samples)\")\n",
    "\n",
    "print(f\"\\n Feature 2 processed: company_size\")\n",
    "print(f\"   Type: {df_clean['company_size'].dtype}\")\n",
    "print(f\"   Range: {df_clean['company_size'].min()} to {df_clean['company_size'].max()}\")\n",
    "print(f\"   Missing: {df_clean['company_size'].isna().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "46f0ce4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 3: company_type\n",
      "======================================================================\n",
      "\n",
      "Step 1: Fill missing values with 'Unknown'\n",
      "Missing before: 6140 (32.05%)\n",
      "Missing after: 0\n",
      "\n",
      "Step 2: One-Hot encoding\n",
      "Categories: ['Early Stage Startup', 'Funded Startup', 'NGO', 'Other', 'Public Sector', 'Pvt Ltd', 'Unknown']\n",
      "Created 7 binary columns:\n",
      "      company_type_Early Stage Startup: 603 samples\n",
      "      company_type_Funded Startup   : 1,001 samples\n",
      "      company_type_NGO              : 521 samples\n",
      "      company_type_Other            : 121 samples\n",
      "      company_type_Public Sector    : 955 samples\n",
      "      company_type_Pvt Ltd          : 9,817 samples\n",
      "      company_type_Unknown          : 6,140 samples\n",
      "\n",
      "Feature 3 processed: company_type\n",
      "   New columns added: 7\n",
      "   Current shape: (19158, 19)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 3: company_type\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 3: company_type\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Handle missing values\n",
    "print(\"\\nStep 1: Fill missing values with 'Unknown'\")\n",
    "missing_count = df_clean['company_type'].isna().sum()\n",
    "print(f\"Missing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "df_clean['company_type'] = df_clean['company_type'].fillna('Unknown')\n",
    "print(f\"Missing after: {df_clean['company_type'].isna().sum()}\")\n",
    "\n",
    "# Step 2: One-Hot encoding\n",
    "print(\"\\nStep 2: One-Hot encoding\")\n",
    "print(f\"Categories: {sorted(df_clean['company_type'].unique())}\")\n",
    "\n",
    "company_type_dummies = pd.get_dummies(df_clean['company_type'], prefix='company_type', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, company_type_dummies], axis=1)\n",
    "df_clean = df_clean.drop('company_type', axis=1)\n",
    "\n",
    "print(f\"Created {len(company_type_dummies.columns)} binary columns:\")\n",
    "for col in sorted(company_type_dummies.columns):\n",
    "    count = df_clean[col].sum()\n",
    "    print(f\"      {col:30s}: {count:,} samples\")\n",
    "\n",
    "print(f\"\\nFeature 3 processed: company_type\")\n",
    "print(f\"   New columns added: {len(company_type_dummies.columns)}\")\n",
    "print(f\"   Current shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "94b54b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 4: gender\n",
      "======================================================================\n",
      "Missing before: 4508 (23.53%)\n",
      "Created 4 columns: ['gender_Female', 'gender_Male', 'gender_Other', 'gender_Unknown']\n",
      "Current shape: (19158, 22)\n",
      "\n",
      "Created 4 columns: ['gender_Female', 'gender_Male', 'gender_Other', 'gender_Unknown']\n",
      "Current shape: (19158, 22)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 4: gender\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 4: gender\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['gender'].isna().sum()\n",
    "print(f\"Missing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "df_clean['gender'] = df_clean['gender'].fillna('Unknown')\n",
    "\n",
    "gender_dummies = pd.get_dummies(df_clean['gender'], prefix='gender', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, gender_dummies], axis=1)\n",
    "df_clean = df_clean.drop('gender', axis=1)\n",
    "\n",
    "print(f\"Created {len(gender_dummies.columns)} columns: {list(gender_dummies.columns)}\")\n",
    "print(f\"Current shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d9528fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 5: major_discipline\n",
      "======================================================================\n",
      "Missing before: 2813 (14.68%)\n",
      "\n",
      "Filling strategy: All missing ‚Üí 'Unknown'\n",
      "Filled 2813 with 'Unknown'\n",
      "Missing after: 0\n",
      "\n",
      "Created 7 columns: ['major_Arts', 'major_Business Degree', 'major_Humanities', 'major_No Major', 'major_Other', 'major_STEM', 'major_Unknown']\n",
      "Current shape: (19158, 28)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 5: major_discipline\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 5: major_discipline\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['major_discipline'].isna().sum()\n",
    "print(f\"Missing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Fill missing with 'Unknown'\n",
    "print(\"\\nFilling strategy: All missing ‚Üí 'Unknown'\")\n",
    "df_clean['major_discipline'] = df_clean['major_discipline'].fillna('Unknown')\n",
    "print(f\"Filled {missing_count} with 'Unknown'\")\n",
    "print(f\"Missing after: {df_clean['major_discipline'].isna().sum()}\")\n",
    "\n",
    "# One-Hot encoding\n",
    "major_dummies = pd.get_dummies(df_clean['major_discipline'], prefix='major', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, major_dummies], axis=1)\n",
    "df_clean = df_clean.drop('major_discipline', axis=1)\n",
    "\n",
    "print(f\"\\nCreated {len(major_dummies.columns)} columns: {list(major_dummies.columns)}\")\n",
    "print(f\"Current shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "69e5f955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 6: experience\n",
      "======================================================================\n",
      "Missing before: 65 (0.34%)\n",
      "   Filled 65 missing with median experience: '9' (value=9)\n",
      "\n",
      "Feature 6 processed: experience\n",
      "   Type: int64\n",
      "   Range: 0 to 25 years\n",
      "   Missing: 0\n",
      "\n",
      "\n",
      "Processing Feature 6: experience\n",
      "======================================================================\n",
      "Missing before: 65 (0.34%)\n",
      "   Filled 65 missing with median experience: '9' (value=9)\n",
      "\n",
      "Feature 6 processed: experience\n",
      "   Type: int64\n",
      "   Range: 0 to 25 years\n",
      "   Missing: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 6: experience\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 6: experience\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['experience'].isna().sum()\n",
    "print(f\"Missing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# First convert to numeric for median calculation\n",
    "exp_mapping = {\n",
    "    '<1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,\n",
    "    '6': 6, '7': 7, '8': 8, '9': 9, '10': 10,\n",
    "    '11': 11, '12': 12, '13': 13, '14': 14, '15': 15,\n",
    "    '16': 16, '17': 17, '18': 18, '19': 19, '20': 20,\n",
    "    '>20': 25 \n",
    "}\n",
    "\n",
    "# Fill missing with median before encoding\n",
    "# Calculate median from non-missing values\n",
    "temp_numeric = df_clean['experience'].dropna().map(exp_mapping)\n",
    "median_value = temp_numeric.median()\n",
    "# Find the closest original value to median\n",
    "median_key = min(exp_mapping.items(), key=lambda x: abs(x[1] - median_value))[0]\n",
    "df_clean['experience'] = df_clean['experience'].fillna(median_key)\n",
    "print(f\"   Filled {missing_count} missing with median experience: '{median_key}' (value={exp_mapping[median_key]})\")\n",
    "\n",
    "# Apply ordinal encoding\n",
    "df_clean['experience'] = df_clean['experience'].map(exp_mapping)\n",
    "\n",
    "print(f\"\\nFeature 6 processed: experience\")\n",
    "print(f\"   Type: {df_clean['experience'].dtype}\")\n",
    "print(f\"   Range: {df_clean['experience'].min()} to {df_clean['experience'].max()} years\")\n",
    "print(f\"   Missing: {df_clean['experience'].isna().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c2418968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 7: education_level\n",
      "======================================================================\n",
      "Filled 460 missing with mode: 'Graduate'\n",
      "\n",
      "Feature 7 processed: education_level\n",
      "Ordinal encoded: range 1-5\n",
      "Missing: 0\n",
      "\n",
      "Filled 460 missing with mode: 'Graduate'\n",
      "\n",
      "Feature 7 processed: education_level\n",
      "Ordinal encoded: range 1-5\n",
      "Missing: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 7: education_level\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 7: education_level\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['education_level'].isna().sum()\n",
    "mode_value = df_clean['education_level'].mode()[0]\n",
    "df_clean['education_level'] = df_clean['education_level'].fillna(mode_value)\n",
    "print(f\"Filled {missing_count} missing with mode: '{mode_value}'\")\n",
    "\n",
    "# Ordinal encoding: Lower education -> Higher values\n",
    "edu_mapping = {\n",
    "    'Primary School': 1,\n",
    "    'High School': 2,\n",
    "    'Graduate': 3,\n",
    "    'Masters': 4,\n",
    "    'Phd': 5\n",
    "}\n",
    "df_clean['education_level'] = df_clean['education_level'].map(edu_mapping)\n",
    "\n",
    "print(f\"\\nFeature 7 processed: education_level\")\n",
    "print(f\"Ordinal encoded: range {df_clean['education_level'].min()}-{df_clean['education_level'].max()}\")\n",
    "print(f\"Missing: {df_clean['education_level'].isna().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "710498d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 8: enrolled_university\n",
      "======================================================================\n",
      "Filled 386 missing with 'no_enrollment'\n",
      "Created 3 columns, shape: (19158, 30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 8: enrolled_university\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 8: enrolled_university\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['enrolled_university'].isna().sum()\n",
    "df_clean['enrolled_university'] = df_clean['enrolled_university'].fillna('no_enrollment')\n",
    "print(f\"Filled {missing_count} missing with 'no_enrollment'\")\n",
    "\n",
    "enrolled_dummies = pd.get_dummies(df_clean['enrolled_university'], prefix='enrolled', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, enrolled_dummies], axis=1)\n",
    "df_clean = df_clean.drop('enrolled_university', axis=1)\n",
    "print(f\"Created {len(enrolled_dummies.columns)} columns, shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9b6124f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 9: relevent_experience\n",
      "======================================================================\n",
      "Missing values: 0\n",
      "\n",
      " Feature 9 processed: relevent_experience\n",
      "   Binary encoded: {1: 13792, 0: 5366}\n",
      "   Missing: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 9: relevent_experience\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 9: relevent_experience\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Missing values: {df_clean['relevent_experience'].isna().sum()}\")\n",
    "\n",
    "# Binary encoding: Has relevent experience -> 1, No experience -> 0\n",
    "df_clean['relevent_experience'] = df_clean['relevent_experience'].map({\n",
    "    'Has relevent experience': 1,\n",
    "    'No relevent experience': 0\n",
    "})\n",
    "\n",
    "print(f\"\\n Feature 9 processed: relevent_experience\")\n",
    "print(f\"   Binary encoded: {df_clean['relevent_experience'].value_counts().to_dict()}\")\n",
    "print(f\"   Missing: {df_clean['relevent_experience'].isna().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "31196115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 10: last_new_job\n",
      "======================================================================\n",
      "Filled 423 missing with mode: '1'\n",
      "Ordinal encoded: range 0-5\n",
      "\n",
      "Filled 423 missing with mode: '1'\n",
      "Ordinal encoded: range 0-5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature 10: last_new_job\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 10: last_new_job\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['last_new_job'].isna().sum()\n",
    "mode_value = df_clean['last_new_job'].mode()[0]\n",
    "df_clean['last_new_job'] = df_clean['last_new_job'].fillna(mode_value)\n",
    "print(f\"Filled {missing_count} missing with mode: '{mode_value}'\")\n",
    "\n",
    "job_mapping = {'never': 0, '1': 1, '2': 2, '3': 3, '4': 4, '>4': 5}\n",
    "df_clean['last_new_job'] = df_clean['last_new_job'].map(job_mapping)\n",
    "print(f\"Ordinal encoded: range {df_clean['last_new_job'].min()}-{df_clean['last_new_job'].max()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f21cb592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Feature 11: city\n",
      "======================================================================\n",
      "Missing values: 0\n",
      "Unique cities: 123\n",
      "Encoder city after split datasets\n",
      "Unique cities: 123\n",
      "Encoder city after split datasets\n"
     ]
    }
   ],
   "source": [
    "# Feature 11: city\n",
    "# cityË¶ÅÂÅötargetÁºñÁ†ÅÔºå‰∏∫Èò≤Ê≠¢Êï∞ÊçÆÊ≥ÑÈú≤ÔºåÂú®ÂàíÂàÜÊï∞ÊçÆÈõÜÂêéÂÜçÁºñÁ†Å\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 11: city\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Missing values: {df_clean['city'].isna().sum()}\")\n",
    "print(f\"Unique cities: {df_clean['city'].nunique()}\")\n",
    "\n",
    "print(\"Encoder city after split datasets\")\n",
    "\n",
    "# # Import TargetEncoder\n",
    "# from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "# # Target encoding for high cardinality categorical feature\n",
    "# # Using cross-validation to prevent overfitting\n",
    "# target_encoder = TargetEncoder(cv=5, smooth='auto', target_type='binary')\n",
    "# df_clean['city_encoded'] = target_encoder.fit_transform(\n",
    "#     df_clean[['city']], \n",
    "#     df_clean['target']\n",
    "# )\n",
    "\n",
    "# # Drop original city column\n",
    "# df_clean = df_clean.drop('city', axis=1)\n",
    "\n",
    "# print(f\"\\nFeature 11 processed: city\")\n",
    "# print(f\"   Target encoded with CV=5\")\n",
    "# print(f\"   Output: 1 numeric column (city_encoded)\")\n",
    "# print(f\"   Range: {df_clean['city_encoded'].min():.4f} to {df_clean['city_encoded'].max():.4f}\")\n",
    "# print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "b1d5c4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Processing Features 12-13: Numeric Features\n",
      "======================================================================\n",
      "city_development_index: Already numeric, no action needed\n",
      "Missing values: 0\n",
      "Range: 0.448 to 0.949\n",
      "\n",
      "training_hours: Already numeric, no action needed\n",
      "Missing values: 0\n",
      "Range: 1 to 336 hours\n",
      "   Shape: (19158, 30)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Features 12-13: city_development_index & training_hours\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Features 12-13: Numeric Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"city_development_index: Already numeric, no action needed\")\n",
    "print(f\"Missing values: {df_clean['city_development_index'].isna().sum()}\")\n",
    "print(f\"Range: {df_clean['city_development_index'].min():.3f} to {df_clean['city_development_index'].max():.3f}\")\n",
    "\n",
    "print(\"\\ntraining_hours: Already numeric, no action needed\")\n",
    "print(f\"Missing values: {df_clean['training_hours'].isna().sum()}\")\n",
    "print(f\"Range: {df_clean['training_hours'].min()} to {df_clean['training_hours'].max()} hours\")\n",
    "\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b480f7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA CLEANING VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "1. Dataset Shape:\n",
      "   Original: (19158, 14)\n",
      "   Cleaned:  (19158, 30)\n",
      "   ‚Üí Rows preserved: 19158 (100%)\n",
      "   ‚Üí Columns changed: 14 ‚Üí 30 (due to One-Hot encoding)\n",
      "\n",
      "2. Missing Values:\n",
      "No missing values! All 574,740 cells are filled\n",
      "\n",
      "3. Data Types:\n",
      "   {dtype('bool'): 21, dtype('int64'): 6, dtype('float64'): 2, dtype('O'): 1}\n",
      "Non-numeric columns found: ['city']\n",
      "\n",
      "4. Final Feature List:\n",
      "   Total features: 29\n",
      "   Features: city, city_development_index, company_size, company_type_Early Stage Startup, company_type_Funded Startup, company_type_NGO, company_type_Other, company_type_Public Sector, company_type_Pvt Ltd, company_type_Unknown...\n",
      "\n",
      "5. Sample of Cleaned Data (first 3 rows):\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "      <th>company_type_Early Stage Startup</th>\n",
       "      <th>company_type_Funded Startup</th>\n",
       "      <th>company_type_NGO</th>\n",
       "      <th>company_type_Other</th>\n",
       "      <th>company_type_Public Sector</th>\n",
       "      <th>company_type_Pvt Ltd</th>\n",
       "      <th>company_type_Unknown</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>gender_Unknown</th>\n",
       "      <th>major_Arts</th>\n",
       "      <th>major_Business Degree</th>\n",
       "      <th>major_Humanities</th>\n",
       "      <th>major_No Major</th>\n",
       "      <th>major_Other</th>\n",
       "      <th>major_STEM</th>\n",
       "      <th>major_Unknown</th>\n",
       "      <th>enrolled_Full time course</th>\n",
       "      <th>enrolled_Part time course</th>\n",
       "      <th>enrolled_no_enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city_40</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city  city_development_index  relevent_experience  education_level  \\\n",
       "0  city_103                   0.920                    1                3   \n",
       "1   city_40                   0.776                    0                3   \n",
       "2   city_21                   0.624                    0                3   \n",
       "\n",
       "   experience  company_size  last_new_job  training_hours  target  \\\n",
       "0          25            -1             1              36     1.0   \n",
       "1          15             2             5              47     0.0   \n",
       "2           5            -1             0              83     0.0   \n",
       "\n",
       "   company_type_Early Stage Startup  company_type_Funded Startup  \\\n",
       "0                             False                        False   \n",
       "1                             False                        False   \n",
       "2                             False                        False   \n",
       "\n",
       "   company_type_NGO  company_type_Other  company_type_Public Sector  \\\n",
       "0             False               False                       False   \n",
       "1             False               False                       False   \n",
       "2             False               False                       False   \n",
       "\n",
       "   company_type_Pvt Ltd  company_type_Unknown  gender_Female  gender_Male  \\\n",
       "0                 False                  True          False         True   \n",
       "1                  True                 False          False         True   \n",
       "2                 False                  True          False        False   \n",
       "\n",
       "   gender_Other  gender_Unknown  major_Arts  major_Business Degree  \\\n",
       "0         False           False       False                  False   \n",
       "1         False           False       False                  False   \n",
       "2         False            True       False                  False   \n",
       "\n",
       "   major_Humanities  major_No Major  major_Other  major_STEM  major_Unknown  \\\n",
       "0             False           False        False        True          False   \n",
       "1             False           False        False        True          False   \n",
       "2             False           False        False        True          False   \n",
       "\n",
       "   enrolled_Full time course  enrolled_Part time course  \\\n",
       "0                      False                      False   \n",
       "1                      False                      False   \n",
       "2                       True                      False   \n",
       "\n",
       "   enrolled_no_enrollment  \n",
       "0                    True  \n",
       "1                    True  \n",
       "2                   False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CLEANING COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verification: Check cleaned data quality\n",
    "print(\"=\"*80)\n",
    "print(\"DATA CLEANING VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Shape comparison\n",
    "print(\"\\n1. Dataset Shape:\")\n",
    "print(f\"   Original: {df.shape}\")\n",
    "print(f\"   Cleaned:  {df_clean.shape}\")\n",
    "print(f\"   ‚Üí Rows preserved: {df_clean.shape[0]} (100%)\")\n",
    "print(f\"   ‚Üí Columns changed: {df.shape[1]} ‚Üí {df_clean.shape[1]} (due to One-Hot encoding)\")\n",
    "\n",
    "# 2. Missing values check\n",
    "print(\"\\n2. Missing Values:\")\n",
    "missing_after = df_clean.isnull().sum().sum()\n",
    "if missing_after == 0:\n",
    "    print(f\"No missing values! All {df_clean.shape[0] * df_clean.shape[1]:,} cells are filled\")\n",
    "else:\n",
    "    print(f\"WARNING: {missing_after} missing values found!\")\n",
    "    print(df_clean.isnull().sum()[df_clean.isnull().sum() > 0])\n",
    "\n",
    "# 3. Data types check\n",
    "print(\"\\n3. Data Types:\")\n",
    "dtypes_summary = df_clean.dtypes.value_counts()\n",
    "print(f\"   {dtypes_summary.to_dict()}\")\n",
    "non_numeric = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "if len(non_numeric) == 0:\n",
    "    print(f\"All features are numeric (ready for modeling)\")\n",
    "else:\n",
    "    print(f\"Non-numeric columns found: {non_numeric}\")\n",
    "\n",
    "# 4. Feature list\n",
    "print(\"\\n4. Final Feature List:\")\n",
    "feature_cols = [col for col in df_clean.columns if col != 'target']\n",
    "print(f\"   Total features: {len(feature_cols)}\")\n",
    "print(f\"   Features: {', '.join(sorted(feature_cols)[:10])}...\")\n",
    "\n",
    "# 5. Display sample\n",
    "print(\"\\n5. Sample of Cleaned Data (first 3 rows):\")\n",
    "print(\"=\"*80)\n",
    "display(df_clean.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA CLEANING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cfbaf2",
   "metadata": {},
   "source": [
    "## 4. Datasets Split & Target Encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52894146",
   "metadata": {},
   "source": [
    "### 4.1 Ready for Split & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a43153f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Êï∞ÊçÆÈõÜÂáÜÂ§á\n",
      "================================================================================\n",
      "ÁâπÂæÅÁü©Èòµ X: (19158, 29)\n",
      "ÁõÆÊ†áÂèòÈáè y: (19158,)\n",
      "\n",
      "ÁõÆÊ†áÂèòÈáèÂàÜÂ∏É:\n",
      "  Class 0 (‰∏çÊç¢Â∑•‰Ωú): 14,381 (75.07%)\n",
      "  Class 1 (Êç¢Â∑•‰Ωú):   4,777 (24.93%)\n",
      "  Á±ªÂà´ÊØî‰æã: 3.01:1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# ÂàÜÁ¶ªÁâπÂæÅÂíåÁõÆÊ†áÂèòÈáè\n",
    "X = df_clean.drop('target', axis=1)\n",
    "y = df_clean['target'].astype(int)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Êï∞ÊçÆÈõÜÂáÜÂ§á\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ÁâπÂæÅÁü©Èòµ X: {X.shape}\")\n",
    "print(f\"ÁõÆÊ†áÂèòÈáè y: {y.shape}\")\n",
    "print(f\"\\nÁõÆÊ†áÂèòÈáèÂàÜÂ∏É:\")\n",
    "print(f\"  Class 0 (‰∏çÊç¢Â∑•‰Ωú): {(y==0).sum():,} ({(y==0).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"  Class 1 (Êç¢Â∑•‰Ωú):   {(y==1).sum():,} ({(y==1).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"  Á±ªÂà´ÊØî‰æã: {(y==0).sum()/(y==1).sum():.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ed13c",
   "metadata": {},
   "source": [
    "### 4.2 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9ee4bcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Á¨¨‰∏ÄÊ¨°ÂàíÂàÜ: ÂàÜÁ¶ªÊµãËØïÈõÜ\n",
      "================================================================================\n",
      "‰∏¥Êó∂ÈõÜ (Train+Val): 15,326 samples (80.0%)\n",
      "ÊµãËØïÈõÜ (Test):      3,832 samples (20.0%)\n",
      "\n",
      "================================================================================\n",
      "Á¨¨‰∫åÊ¨°ÂàíÂàÜ: ÂàÜÁ¶ªÈ™åËØÅÈõÜ\n",
      "================================================================================\n",
      "ËÆ≠ÁªÉÈõÜ (Train):      11,494 samples (60.0%)\n",
      "È™åËØÅÈõÜ (Validation): 3,832 samples (20.0%)\n",
      "\n",
      "================================================================================\n",
      "ÊúÄÁªàÊï∞ÊçÆÈõÜÂàíÂàÜÁªìÊûú\n",
      "================================================================================\n",
      "ËÆ≠ÁªÉÈõÜ:   11,494 samples (60.0%) - Áî®‰∫éËÆ≠ÁªÉÊ®°Âûã\n",
      "È™åËØÅÈõÜ:   3,832 samples (20.0%) - Áî®‰∫éË∞ÉÂèÇÂíåÊ®°ÂûãÈÄâÊã©\n",
      "ÊµãËØïÈõÜ:   3,832 samples (20.0%) - Áî®‰∫éÊúÄÁªàËØÑ‰º∞\n",
      "ÊÄªËÆ°:     19,158 samples (100%)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Á¨¨‰∏ÄÊ¨°ÂàíÂàÜ - ÂàÜÁ¶ªÂá∫ÊµãËØïÈõÜ (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,           # 20% ‰Ωú‰∏∫ÊµãËØïÈõÜ\n",
    "    stratify=y,               # ÂàÜÂ±ÇÊäΩÊ†∑,‰øùÊåÅÁ±ªÂà´ÊØî‰æã\n",
    "    random_state=42           # Âõ∫ÂÆöÈöèÊú∫ÁßçÂ≠ê,Á°Æ‰øùÂèØÂ§çÁé∞\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Á¨¨‰∏ÄÊ¨°ÂàíÂàÜ: ÂàÜÁ¶ªÊµãËØïÈõÜ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‰∏¥Êó∂ÈõÜ (Train+Val): {X_temp.shape[0]:,} samples ({X_temp.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"ÊµãËØïÈõÜ (Test):      {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Step 2: Á¨¨‰∫åÊ¨°ÂàíÂàÜ - Â∞Ü‰∏¥Êó∂ÈõÜÂàÜ‰∏∫ËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜ\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.25,           # 0.25 * 80% = 20% (Áõ∏ÂØπ‰∫éÂéüÂßãÊï∞ÊçÆ)\n",
    "    stratify=y_temp,          # ÂàÜÂ±ÇÊäΩÊ†∑\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Á¨¨‰∫åÊ¨°ÂàíÂàÜ: ÂàÜÁ¶ªÈ™åËØÅÈõÜ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ËÆ≠ÁªÉÈõÜ (Train):      {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"È™åËØÅÈõÜ (Validation): {X_val.shape[0]:,} samples ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ÊúÄÁªàÊï∞ÊçÆÈõÜÂàíÂàÜÁªìÊûú\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ËÆ≠ÁªÉÈõÜ:   {X_train.shape[0]:,} samples ({X_train.shape[0]/len(X)*100:.1f}%) - Áî®‰∫éËÆ≠ÁªÉÊ®°Âûã\")\n",
    "print(f\"È™åËØÅÈõÜ:   {X_val.shape[0]:,} samples ({X_val.shape[0]/len(X)*100:.1f}%) - Áî®‰∫éË∞ÉÂèÇÂíåÊ®°ÂûãÈÄâÊã©\")\n",
    "print(f\"ÊµãËØïÈõÜ:   {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%) - Áî®‰∫éÊúÄÁªàËØÑ‰º∞\")\n",
    "print(f\"ÊÄªËÆ°:     {len(X):,} samples (100%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aced7d3",
   "metadata": {},
   "source": [
    "**Validation quality of splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "58834ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Á±ªÂà´ÂàÜÂ∏ÉÈ™åËØÅ (ÂàÜÂ±ÇÊäΩÊ†∑Ë¥®ÈáèÊ£ÄÊü•)\n",
      "================================================================================\n",
      "\n",
      "Êï∞ÊçÆÈõÜ             Ê†∑Êú¨Êï∞          Class 0         Class 1         ÊØî‰æã        \n",
      "--------------------------------------------------------------------------------\n",
      "ÂéüÂßãÊï∞ÊçÆ            19,158       14,381  (75.07%)  4,777   (24.93%)  3.01:1\n",
      "ËÆ≠ÁªÉÈõÜ             11,494       8,628   (75.07%)  2,866   (24.93%)  3.01:1\n",
      "È™åËØÅÈõÜ             3,832        2,876   (75.05%)  956     (24.95%)  3.01:1\n",
      "ÊµãËØïÈõÜ             3,832        2,877   (75.08%)  955     (24.92%)  3.01:1\n",
      "\n",
      "‚úì Â¶ÇÊûúÊâÄÊúâÂ≠êÈõÜÁöÑÊØî‰æãÊé•ËøëÂéüÂßãÊï∞ÊçÆ,ËØ¥ÊòéÂàÜÂ±ÇÊäΩÊ†∑ÊàêÂäü!\n"
     ]
    }
   ],
   "source": [
    "# È™åËØÅÊØè‰∏™Â≠êÈõÜÁöÑÁ±ªÂà´ÂàÜÂ∏É\n",
    "print(\"=\"*80)\n",
    "print(\"Á±ªÂà´ÂàÜÂ∏ÉÈ™åËØÅ (ÂàÜÂ±ÇÊäΩÊ†∑Ë¥®ÈáèÊ£ÄÊü•)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "datasets = [\n",
    "    (\"ÂéüÂßãÊï∞ÊçÆ\", y),\n",
    "    (\"ËÆ≠ÁªÉÈõÜ\", y_train),\n",
    "    (\"È™åËØÅÈõÜ\", y_val),\n",
    "    (\"ÊµãËØïÈõÜ\", y_test)\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Êï∞ÊçÆÈõÜ':<15} {'Ê†∑Êú¨Êï∞':<12} {'Class 0':<15} {'Class 1':<15} {'ÊØî‰æã':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, target in datasets:\n",
    "    total = len(target)\n",
    "    class_0 = (target == 0).sum()\n",
    "    class_1 = (target == 1).sum()\n",
    "    ratio = class_0 / class_1\n",
    "    print(f\"{name:<15} {total:<12,} {class_0:<7,} ({class_0/total*100:5.2f}%)  {class_1:<7,} ({class_1/total*100:5.2f}%)  {ratio:.2f}:1\")\n",
    "\n",
    "print(\"\\n‚úì Â¶ÇÊûúÊâÄÊúâÂ≠êÈõÜÁöÑÊØî‰æãÊé•ËøëÂéüÂßãÊï∞ÊçÆ,ËØ¥ÊòéÂàÜÂ±ÇÊäΩÊ†∑ÊàêÂäü!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0006cca",
   "metadata": {},
   "source": [
    "### 4.3 Encoding city with Target Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d17e9f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Feature 11: city - Target Encoding (Êó†Êï∞ÊçÆÊ≥ÑÈú≤ÁâàÊú¨)\n",
      "================================================================================\n",
      "\n",
      "Step 1: Âú®ËÆ≠ÁªÉÈõÜ‰∏äËÆ≠ÁªÉÁºñÁ†ÅÂô®\n",
      "ËÆ≠ÁªÉÈõÜÂüéÂ∏ÇÊï∞: 121\n",
      "Ê†∑Êú¨Êï∞: 11,494\n",
      "‚úì ÁºñÁ†ÅÂô®ËÆ≠ÁªÉÂÆåÊàê (‰ªÖ‰ΩøÁî®ËÆ≠ÁªÉÈõÜÊï∞ÊçÆ)\n",
      "\n",
      "Step 2: ÁºñÁ†ÅËÆ≠ÁªÉÈõÜ\n",
      "‚úì ËÆ≠ÁªÉÈõÜÁºñÁ†ÅÂÆåÊàê\n",
      "   ÁºñÁ†ÅËåÉÂõ¥: 0.0000 to 1.0000\n",
      "\n",
      "Step 3: ÁºñÁ†ÅÈ™åËØÅÈõÜ (‰ΩøÁî®ËÆ≠ÁªÉÈõÜÂ≠¶Âà∞ÁöÑÁºñÁ†Å)\n",
      "‚úì È™åËØÅÈõÜÁºñÁ†ÅÂÆåÊàê\n",
      "   È™åËØÅÈõÜÂüéÂ∏ÇÊï∞: 112\n",
      "\n",
      "Step 4: ÁºñÁ†ÅÊµãËØïÈõÜ (‰ΩøÁî®ËÆ≠ÁªÉÈõÜÂ≠¶Âà∞ÁöÑÁºñÁ†Å)\n",
      "‚úì ÊµãËØïÈõÜÁºñÁ†ÅÂÆåÊàê\n",
      "   ÊµãËØïÈõÜÂüéÂ∏ÇÊï∞: 117\n",
      "\n",
      "================================================================================\n",
      "Target Encoding ÂÆåÊàê (Êó†Êï∞ÊçÆÊ≥ÑÈú≤)\n",
      "================================================================================\n",
      "ËÆ≠ÁªÉÈõÜ: (11494, 29)\n",
      "È™åËØÅÈõÜ: (3832, 29)\n",
      "ÊµãËØïÈõÜ: (3832, 29)\n",
      "\n",
      "ÊâÄÊúâÁâπÂæÅÁé∞Âú®ÈÉΩÊòØÊï∞ÂÄºÂûã,ÂèØ‰ª•Áõ¥Êé•Áî®‰∫éÊ®°ÂûãËÆ≠ÁªÉ!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Feature 11: city - Target Encoding (Êó†Êï∞ÊçÆÊ≥ÑÈú≤ÁâàÊú¨)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ÂàùÂßãÂåñTarget Encoder\n",
    "target_encoder = TargetEncoder(\n",
    "    cv=5,                    # 5Êäò‰∫§ÂèâÈ™åËØÅ,Èò≤Ê≠¢ËøáÊãüÂêà\n",
    "    smooth='auto',           # Ëá™Âä®Âπ≥Êªë,Â§ÑÁêÜ‰ΩéÈ¢ëÂüéÂ∏Ç\n",
    "    target_type='binary'     # ‰∫åÂàÜÁ±ªÁõÆÊ†á\n",
    ")\n",
    "\n",
    "# Step 1: Âú®ËÆ≠ÁªÉÈõÜ‰∏äfit (Â≠¶‰π†ÊØè‰∏™ÂüéÂ∏ÇÁöÑÁºñÁ†Å)\n",
    "print(\"\\nStep 1: Âú®ËÆ≠ÁªÉÈõÜ‰∏äËÆ≠ÁªÉÁºñÁ†ÅÂô®\")\n",
    "print(f\"ËÆ≠ÁªÉÈõÜÂüéÂ∏ÇÊï∞: {X_train['city'].nunique()}\")\n",
    "print(f\"Ê†∑Êú¨Êï∞: {len(X_train):,}\")\n",
    "\n",
    "target_encoder.fit(X_train[['city']], y_train)\n",
    "print(\"‚úì ÁºñÁ†ÅÂô®ËÆ≠ÁªÉÂÆåÊàê (‰ªÖ‰ΩøÁî®ËÆ≠ÁªÉÈõÜÊï∞ÊçÆ)\")\n",
    "\n",
    "# Step 2: TransformËÆ≠ÁªÉÈõÜ\n",
    "print(\"\\nStep 2: ÁºñÁ†ÅËÆ≠ÁªÉÈõÜ\")\n",
    "X_train_encoded = X_train.copy()\n",
    "X_train_encoded['city_encoded'] = target_encoder.transform(X_train[['city']])\n",
    "X_train_encoded = X_train_encoded.drop('city', axis=1)\n",
    "print(f\"‚úì ËÆ≠ÁªÉÈõÜÁºñÁ†ÅÂÆåÊàê\")\n",
    "print(f\"   ÁºñÁ†ÅËåÉÂõ¥: {X_train_encoded['city_encoded'].min():.4f} to {X_train_encoded['city_encoded'].max():.4f}\")\n",
    "\n",
    "# Step 3: TransformÈ™åËØÅÈõÜ\n",
    "print(\"\\nStep 3: ÁºñÁ†ÅÈ™åËØÅÈõÜ (‰ΩøÁî®ËÆ≠ÁªÉÈõÜÂ≠¶Âà∞ÁöÑÁºñÁ†Å)\")\n",
    "X_val_encoded = X_val.copy()\n",
    "X_val_encoded['city_encoded'] = target_encoder.transform(X_val[['city']])\n",
    "X_val_encoded = X_val_encoded.drop('city', axis=1)\n",
    "print(f\"‚úì È™åËØÅÈõÜÁºñÁ†ÅÂÆåÊàê\")\n",
    "print(f\"   È™åËØÅÈõÜÂüéÂ∏ÇÊï∞: {X_val['city'].nunique()}\")\n",
    "\n",
    "# Step 4: TransformÊµãËØïÈõÜ\n",
    "print(\"\\nStep 4: ÁºñÁ†ÅÊµãËØïÈõÜ (‰ΩøÁî®ËÆ≠ÁªÉÈõÜÂ≠¶Âà∞ÁöÑÁºñÁ†Å)\")\n",
    "X_test_encoded = X_test.copy()\n",
    "X_test_encoded['city_encoded'] = target_encoder.transform(X_test[['city']])\n",
    "X_test_encoded = X_test_encoded.drop('city', axis=1)\n",
    "print(f\"‚úì ÊµãËØïÈõÜÁºñÁ†ÅÂÆåÊàê\")\n",
    "print(f\"   ÊµãËØïÈõÜÂüéÂ∏ÇÊï∞: {X_test['city'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Target Encoding ÂÆåÊàê (Êó†Êï∞ÊçÆÊ≥ÑÈú≤)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ËÆ≠ÁªÉÈõÜ: {X_train_encoded.shape}\")\n",
    "print(f\"È™åËØÅÈõÜ: {X_val_encoded.shape}\")\n",
    "print(f\"ÊµãËØïÈõÜ: {X_test_encoded.shape}\")\n",
    "print(f\"\\nÊâÄÊúâÁâπÂæÅÁé∞Âú®ÈÉΩÊòØÊï∞ÂÄºÂûã,ÂèØ‰ª•Áõ¥Êé•Áî®‰∫éÊ®°ÂûãËÆ≠ÁªÉ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99dcf20",
   "metadata": {},
   "source": [
    "### 4.4 Final Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "96216e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ÊúÄÁªàÊï∞ÊçÆÈõÜÊëòË¶Å\n",
      "================================================================================\n",
      "\n",
      "1. Êï∞ÊçÆÈõÜÂΩ¢Áä∂:\n",
      "   ËÆ≠ÁªÉÈõÜ: X_train_encoded (11494, 29), y_train (11494,)\n",
      "   È™åËØÅÈõÜ: X_val_encoded   (3832, 29), y_val   (3832,)\n",
      "   ÊµãËØïÈõÜ: X_test_encoded  (3832, 29), y_test  (3832,)\n",
      "\n",
      "2. ÁâπÂæÅÊï∞Èáè:\n",
      "   ÊÄªÁâπÂæÅÊï∞: 29\n",
      "\n",
      "3. Áº∫Â§±ÂÄºÊ£ÄÊü•:\n",
      "   ËÆ≠ÁªÉÈõÜÁº∫Â§±: 0\n",
      "   È™åËØÅÈõÜÁº∫Â§±: 0\n",
      "   ÊµãËØïÈõÜÁº∫Â§±: 0\n",
      "\n",
      "4. ÁâπÂæÅÂàóË°® (Ââç15‰∏™):\n",
      "    1. city_development_index\n",
      "    2. relevent_experience\n",
      "    3. education_level\n",
      "    4. experience\n",
      "    5. company_size\n",
      "    6. last_new_job\n",
      "    7. training_hours\n",
      "    8. company_type_Early Stage Startup\n",
      "    9. company_type_Funded Startup\n",
      "   10. company_type_NGO\n",
      "   11. company_type_Other\n",
      "   12. company_type_Public Sector\n",
      "   13. company_type_Pvt Ltd\n",
      "   14. company_type_Unknown\n",
      "   15. gender_Female\n",
      "   16. gender_Male\n",
      "   17. gender_Other\n",
      "   18. gender_Unknown\n",
      "   19. major_Arts\n",
      "   20. major_Business Degree\n",
      "   21. major_Humanities\n",
      "   22. major_No Major\n",
      "   23. major_Other\n",
      "   24. major_STEM\n",
      "   25. major_Unknown\n",
      "   26. enrolled_Full time course\n",
      "   27. enrolled_Part time course\n",
      "   28. enrolled_no_enrollment\n",
      "   29. city_encoded\n",
      "\n",
      "5. Êï∞ÊçÆÊ†∑Êú¨ (ËÆ≠ÁªÉÈõÜÂâç3Ë°å):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>company_type_Early Stage Startup</th>\n",
       "      <th>company_type_Funded Startup</th>\n",
       "      <th>company_type_NGO</th>\n",
       "      <th>company_type_Other</th>\n",
       "      <th>company_type_Public Sector</th>\n",
       "      <th>company_type_Pvt Ltd</th>\n",
       "      <th>company_type_Unknown</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Other</th>\n",
       "      <th>gender_Unknown</th>\n",
       "      <th>major_Arts</th>\n",
       "      <th>major_Business Degree</th>\n",
       "      <th>major_Humanities</th>\n",
       "      <th>major_No Major</th>\n",
       "      <th>major_Other</th>\n",
       "      <th>major_STEM</th>\n",
       "      <th>major_Unknown</th>\n",
       "      <th>enrolled_Full time course</th>\n",
       "      <th>enrolled_Part time course</th>\n",
       "      <th>enrolled_no_enrollment</th>\n",
       "      <th>city_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.178999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17182</th>\n",
       "      <td>0.624</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.596042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7759</th>\n",
       "      <td>0.804</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.198041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_development_index  relevent_experience  education_level  \\\n",
       "2717                    0.903                    0                2   \n",
       "17182                   0.624                    1                3   \n",
       "7759                    0.804                    1                3   \n",
       "\n",
       "       experience  company_size  last_new_job  training_hours  \\\n",
       "2717            1            -1             0             122   \n",
       "17182           3            -1             1             270   \n",
       "7759           14             2             2              48   \n",
       "\n",
       "       company_type_Early Stage Startup  company_type_Funded Startup  \\\n",
       "2717                              False                        False   \n",
       "17182                             False                        False   \n",
       "7759                              False                        False   \n",
       "\n",
       "       company_type_NGO  company_type_Other  company_type_Public Sector  \\\n",
       "2717              False               False                       False   \n",
       "17182             False               False                       False   \n",
       "7759              False               False                        True   \n",
       "\n",
       "       company_type_Pvt Ltd  company_type_Unknown  gender_Female  gender_Male  \\\n",
       "2717                  False                  True          False        False   \n",
       "17182                 False                  True          False         True   \n",
       "7759                  False                 False          False        False   \n",
       "\n",
       "       gender_Other  gender_Unknown  major_Arts  major_Business Degree  \\\n",
       "2717          False            True       False                  False   \n",
       "17182         False           False       False                  False   \n",
       "7759          False            True       False                  False   \n",
       "\n",
       "       major_Humanities  major_No Major  major_Other  major_STEM  \\\n",
       "2717              False           False        False       False   \n",
       "17182             False           False        False        True   \n",
       "7759              False           False        False        True   \n",
       "\n",
       "       major_Unknown  enrolled_Full time course  enrolled_Part time course  \\\n",
       "2717            True                       True                      False   \n",
       "17182          False                       True                      False   \n",
       "7759           False                      False                      False   \n",
       "\n",
       "       enrolled_no_enrollment  city_encoded  \n",
       "2717                    False      0.178999  \n",
       "17182                   False      0.596042  \n",
       "7759                     True      0.198041  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úì Êï∞ÊçÆÈõÜÂàíÂàÜÂíåÁºñÁ†ÅÂÆåÊàê! ÂáÜÂ§áËøõË°åÊ®°ÂûãËÆ≠ÁªÉ\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ÊúÄÁªàÊï∞ÊçÆÈõÜÊëòË¶Å\n",
    "print(\"=\"*80)\n",
    "print(\"ÊúÄÁªàÊï∞ÊçÆÈõÜÊëòË¶Å\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Êï∞ÊçÆÈõÜÂΩ¢Áä∂:\")\n",
    "print(f\"   ËÆ≠ÁªÉÈõÜ: X_train_encoded {X_train_encoded.shape}, y_train {y_train.shape}\")\n",
    "print(f\"   È™åËØÅÈõÜ: X_val_encoded   {X_val_encoded.shape}, y_val   {y_val.shape}\")\n",
    "print(f\"   ÊµãËØïÈõÜ: X_test_encoded  {X_test_encoded.shape}, y_test  {y_test.shape}\")\n",
    "\n",
    "print(\"\\n2. ÁâπÂæÅÊï∞Èáè:\")\n",
    "print(f\"   ÊÄªÁâπÂæÅÊï∞: {X_train_encoded.shape[1]}\")\n",
    "\n",
    "print(\"\\n3. Áº∫Â§±ÂÄºÊ£ÄÊü•:\")\n",
    "print(f\"   ËÆ≠ÁªÉÈõÜÁº∫Â§±: {X_train_encoded.isnull().sum().sum()}\")\n",
    "print(f\"   È™åËØÅÈõÜÁº∫Â§±: {X_val_encoded.isnull().sum().sum()}\")\n",
    "print(f\"   ÊµãËØïÈõÜÁº∫Â§±: {X_test_encoded.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\n4. ÁâπÂæÅÂàóË°® (Ââç15‰∏™):\")\n",
    "feature_cols = X_train_encoded.columns.tolist()\n",
    "for i, col in enumerate(feature_cols[:], 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "\n",
    "print(\"\\n5. Êï∞ÊçÆÊ†∑Êú¨ (ËÆ≠ÁªÉÈõÜÂâç3Ë°å):\")\n",
    "display(X_train_encoded.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Êï∞ÊçÆÈõÜÂàíÂàÜÂíåÁºñÁ†ÅÂÆåÊàê! ÂáÜÂ§áËøõË°åÊ®°ÂûãËÆ≠ÁªÉ\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
