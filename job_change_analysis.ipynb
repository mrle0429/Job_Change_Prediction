{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a81d8f",
   "metadata": {},
   "source": [
    "# Data Science Job Change Prediction\n",
    "- Author: Le Liu\n",
    "- Course: COMP3010J Machine Learning\n",
    "\n",
    "\n",
    "## 1. Project Overview\n",
    "\n",
    "This project aims to predict whether a candidate is looking for a job change based on various demographic and professional features. Then infer the key factors influencing their decision.\n",
    "\n",
    "**Dataset:** `data-science-job-change.csv`\n",
    "\n",
    "**Problem Type:** Binary Classification\n",
    "\n",
    "**Target Variable:** `target` (1.0 = Looking for job change, 0.0 = Not looking for job change)\n",
    "\n",
    "\n",
    "\n",
    "*Project Structure*\n",
    "\n",
    "1. **Introduction** - Project overview and objectives\n",
    "2. **Load and Analyse Data** - Data loading and initial exploration\n",
    "3. **Data Cleaning** - Handle missing values and data quality issues\n",
    "4. **Data Visualisation** - Exploratory data analysis with plots\n",
    "5. **Attribute Selection** - Feature selection and engineering\n",
    "6. **Model Selection and Experiments** - Train and compare models\n",
    "7. **Final Model Training** - Train the best model\n",
    "8. **Further Analysis and Discussion** - Model interpretation\n",
    "9. **Discussion** - Conclusions and future work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff6ec4c",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('data-science-job-change.csv')\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405bd547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(\"=\"*60)\n",
    "numerical_cols = ['city_development_index', 'training_hours', 'target']\n",
    "df[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(3),\n",
    "    'Data_Type': df.dtypes,\n",
    "    'Unique_Values': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "\n",
    "missing_data = missing_data.sort_values(by='Missing_Percentage', ascending=False)\n",
    "print(\"Data Health Report:\")\n",
    "print(\"=\"*80)\n",
    "print(missing_data.to_string(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21f389",
   "metadata": {},
   "source": [
    "### 2.1 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bbb356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Target variable analysis\n",
    "print(\"=\" * 80)\n",
    "print(\"TARGET VARIABLE ANALYSIS: 'target' (Job Change Intention)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "target_counts = df['target'].value_counts().sort_index()\n",
    "target_pct = df['target'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(\"-\" * 50)\n",
    "for val, count, pct in zip(target_counts.index, target_counts.values, target_pct.values):\n",
    "    label = \"Not Looking for Change\" if val == 0.0 else \"Looking for Change\"\n",
    "    print(f\"  Class {int(val)} ({label:25s}): {count:>6,} ({pct:>5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "imbalance_ratio = target_counts.max() / target_counts.min()\n",
    "print(f\"\\nImbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "axes[0].bar(target_counts.index, target_counts.values, color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "axes[0].set_xlabel('Target Class', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Target Variable Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels(['Not Looking\\nfor Change (0)', 'Looking for\\nChange (1)'])\n",
    "for i, (val, count) in enumerate(zip(target_counts.index, target_counts.values)):\n",
    "    axes[0].text(i, count, f'{count:,}\\n({target_pct.values[i]:.1f}%)', \n",
    "                 ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "axes[1].pie(target_counts.values, labels=['Not Looking (0)', 'Looking (1)'], \n",
    "           autopct='%1.1f%%', colors=colors, startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "axes[1].set_title('Target Class Proportion', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8eed09",
   "metadata": {},
   "source": [
    "### 2.2 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939fe23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Select numerical features\n",
    "numerical_features = ['city_development_index', 'training_hours']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NUMERICAL FEATURES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Detailed statistics for each numerical feature\n",
    "for col in numerical_features:\n",
    "    print(f\"\\nFeature: '{col}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"   Count:    {len(data):>10,}\")\n",
    "    print(f\"   Mean:     {data.mean():>10.4f}\")\n",
    "    print(f\"   Median:   {data.median():>10.4f}\")\n",
    "    print(f\"   Std Dev:  {data.std():>10.4f}\")\n",
    "    print(f\"   Min:      {data.min():>10.4f}\")\n",
    "    print(f\"   Max:      {data.max():>10.4f}\")\n",
    "    print(f\"   Range:    {data.max() - data.min():>10.4f}\")\n",
    "    print(f\"   Value Range: [{data.min()}, {data.max()}]\")\n",
    "    \n",
    "    # Distribution shape\n",
    "    skewness = stats.skew(data)\n",
    "    kurtosis = stats.kurtosis(data)\n",
    "    print(f\"\\n   Skewness: {skewness:>10.4f}  \", end=\"\")\n",
    "    if abs(skewness) < 0.5:\n",
    "        print(\"(Nearly symmetric)\")\n",
    "    elif skewness > 0:\n",
    "        print(\"(Right-skewed / Positive skew)\")\n",
    "    else:\n",
    "        print(\"Left-skewed / Negative skew)\")\n",
    "    \n",
    "    print(f\"   Kurtosis: {kurtosis:>10.4f}  \", end=\"\")\n",
    "    if abs(kurtosis) < 1:\n",
    "        print(\"(Normal tail)\")\n",
    "    elif kurtosis > 0:\n",
    "        print(\"(Heavy-tailed / Outliers present)\")\n",
    "    else:\n",
    "        print(\"(Light-tailed)\")\n",
    "    \n",
    "    # Outlier detection (IQR method)\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
    "    \n",
    "    print(f\"\\n   Outliers: {len(outliers):>10,} ({len(outliers)/len(data)*100:.2f}%)\")\n",
    "    print(f\"   IQR Range: [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Numerical Features Distribution Analysis', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "for idx, col in enumerate(numerical_features):\n",
    "    data = df[col].dropna()\n",
    "    \n",
    "    # Histogram with KDE\n",
    "    axes[idx, 0].hist(data, bins=50, edgecolor='black', alpha=0.7, color='steelblue', density=True)\n",
    "    data.plot(kind='kde', ax=axes[idx, 0], color='red', linewidth=2)\n",
    "    axes[idx, 0].set_title(f'{col} - Distribution', fontweight='bold')\n",
    "    axes[idx, 0].set_xlabel(col)\n",
    "    axes[idx, 0].set_ylabel('Density')\n",
    "    axes[idx, 0].axvline(data.mean(), color='green', linestyle='--', linewidth=2, label=f'Mean: {data.mean():.2f}')\n",
    "    axes[idx, 0].axvline(data.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {data.median():.2f}')\n",
    "    axes[idx, 0].legend()\n",
    "    \n",
    "    # Box plot\n",
    "    axes[idx, 1].boxplot(data, vert=False, patch_artist=True,\n",
    "                        boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "                        medianprops=dict(color='red', linewidth=2),\n",
    "                        whiskerprops=dict(color='blue'),\n",
    "                        capprops=dict(color='blue'))\n",
    "    axes[idx, 1].set_title(f'{col} - Box Plot (Outlier Detection)', fontweight='bold')\n",
    "    axes[idx, 1].set_xlabel(col)\n",
    "    axes[idx, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7acaf",
   "metadata": {},
   "source": [
    "### 2.3 Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a31a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "categorical_features = ['city', 'gender', 'relevent_experience', 'enrolled_university', \n",
    "                        'education_level', 'major_discipline', 'experience', \n",
    "                        'company_size', 'company_type', 'last_new_job']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CATEGORICAL FEATURES - UNIQUE VALUES OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cat_summary = []\n",
    "for col in categorical_features:\n",
    "    n_unique = df[col].nunique()\n",
    "    n_missing = df[col].isnull().sum()\n",
    "    missing_pct = (n_missing / len(df)) * 100\n",
    "    \n",
    "    cat_summary.append({\n",
    "        'Feature': col,\n",
    "        'Unique_Values': n_unique,\n",
    "        'Missing_Count': n_missing,\n",
    "        'Missing_%': f\"{missing_pct:.1f}%\"\n",
    "    })\n",
    "\n",
    "cat_df = pd.DataFrame(cat_summary)\n",
    "print(\"\\n\" + cat_df.to_string(index=False))\n",
    "\n",
    "# Detailed display for features with reasonable number of categories (exclude 'city')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED VALUES FOR EACH FEATURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in categorical_features:\n",
    "    n_unique = df[col].nunique()\n",
    "    \n",
    "    # Skip features with too many unique values (like 'city' with 123 values)\n",
    "    if n_unique > 25:\n",
    "        print(f\"\\nFeature: '{col}'\")\n",
    "        print(f\"   Unique Values: {n_unique} (too many to display)\")\n",
    "        continue\n",
    "    \n",
    "    # Display all unique values for features with reasonable cardinality\n",
    "    print(f\"Feature: '{col}'\")\n",
    "    print(f\"   Unique Values: {n_unique}\")\n",
    "    \n",
    "    # Get value counts including missing\n",
    "    value_counts = df[col].value_counts(dropna=False)\n",
    "    \n",
    "    print(f\"   All Values: \", end=\"\")\n",
    "    all_values = df[col].dropna().unique().tolist()\n",
    "    \n",
    "\n",
    "    print()\n",
    "    for val in sorted([str(v) for v in all_values]):\n",
    "        count = value_counts.get(val, 0)\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"      â€¢ {val:30s}  ({count:>6,} samples, {pct:>5.2f}%)\")\n",
    "        \n",
    "    # Show missing values if any\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"      â€¢ [MISSING]                       ({missing_count:>6,} samples, {missing_count/len(df)*100:>5.2f}%)\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16af4820",
   "metadata": {},
   "source": [
    "### 2.5 Feature vs Target - Relationship Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72359f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key features' relationship with target variable\n",
    "key_features = ['relevent_experience', 'company_size', 'company_type', 'education_level']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE vs TARGET RELATIONSHIP ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in key_features:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Feature: '{col}' vs Target (Job Change Intention)\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    # Create crosstab without margins first\n",
    "    crosstab = pd.crosstab(df[col], df['target'], dropna=False)\n",
    "    \n",
    "    # Calculate percentages (target=1 rate for each category)\n",
    "    target_rate = pd.crosstab(df[col], df['target'], normalize='index', dropna=False)\n",
    "    \n",
    "    # Combine into summary\n",
    "    summary_data = []\n",
    "    for cat in crosstab.index:\n",
    "        total = crosstab.loc[cat].sum()\n",
    "        target_0 = crosstab.loc[cat, 0.0] if 0.0 in crosstab.columns else 0\n",
    "        target_1 = crosstab.loc[cat, 1.0] if 1.0 in crosstab.columns else 0\n",
    "        rate_1 = target_rate.loc[cat, 1.0] * 100 if 1.0 in target_rate.columns else 0\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Category': cat,\n",
    "            'Total_Count': int(total),\n",
    "            'Target=0': int(target_0),\n",
    "            'Target=1': int(target_1),\n",
    "            'Target=1_Rate': f\"{rate_1:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    summary = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\" + summary.to_string(index=False))\n",
    "    \n",
    "    # Highlight significant differences\n",
    "    rates = [float(row['Target=1_Rate'].rstrip('%')) for row in summary_data]\n",
    "    avg_rate = np.mean(rates)\n",
    "    print(f\"\\n   Average Target=1 Rate: {avg_rate:.2f}%\")\n",
    "    \n",
    "    high_rate = [row['Category'] for row, rate in zip(summary_data, rates) if rate > avg_rate + 5]\n",
    "    low_rate = [row['Category'] for row, rate in zip(summary_data, rates) if rate < avg_rate - 5]\n",
    "    \n",
    "    if high_rate:\n",
    "        print(f\"Higher likelihood of job change: {high_rate}\")\n",
    "    if low_rate:\n",
    "        print(f\"Lower likelihood of job change: {low_rate}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f313ab56",
   "metadata": {},
   "source": [
    "### 2.6 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Duplicate rows check\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Duplicate Rows: {duplicate_count}\")\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Found {duplicate_count} duplicate rows\")\n",
    "    print(f\"Action: Review and consider removing duplicates\")\n",
    "else:\n",
    "    print(\"No duplicate rows found\")\n",
    "\n",
    "# 2. Duplicate enrollee_id check\n",
    "duplicate_ids = df['enrollee_id'].duplicated().sum()\n",
    "print(f\"Duplicate Enrollee IDs: {duplicate_ids}\")\n",
    "if duplicate_ids > 0:\n",
    "    print(f\"Found {duplicate_ids} duplicate IDs - possible data entry errors\")\n",
    "else:\n",
    "    print(\"All enrollee IDs are unique\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31b303",
   "metadata": {},
   "source": [
    "### 2.8 Summary of Data Analysis Findings\n",
    "\n",
    "**Key Insights from Exploratory Data Analysis:**\n",
    "\n",
    "**Target Variable**\n",
    "- Check class balance and imbalance ratio\n",
    "- Determine if sampling/weighting strategies are needed\n",
    "\n",
    "**Numerical Features (2 features)**\n",
    "- **Distribution shape**: Skewness & Kurtosis analysis\n",
    "- **Outlier detection**: IQR method for anomaly identification\n",
    "- **Statistical summary**: Mean, median, std, range\n",
    "\n",
    "**Categorical Features (10 features)**\n",
    "- **Unique values count**: Understanding cardinality\n",
    "- **Missing data**: Identify features requiring imputation\n",
    "- **Frequency distribution**: Find rare/dominant categories\n",
    "- **Feature-Target relationship**: Identify predictive patterns\n",
    "\n",
    "**Data Quality**\n",
    "- Duplicate records check\n",
    "- ID uniqueness validation\n",
    "- Format consistency (e.g., `company_size` \"10/49\" issue)\n",
    "- Range validation for numerical features\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:** Based on findings, proceed to Data Visualisation and then Data Cleaning (Section 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bedcba3",
   "metadata": {},
   "source": [
    "### 2.9 Key Data Visualisations\n",
    "\n",
    "In this section, we visualize the relationships between key features and the target variable to gain insights into what factors influence job change decisions.\n",
    "\n",
    "**Visualisation Strategy:**\n",
    "1. **Categorical Features vs Target** - Compare job change rates across categories\n",
    "2. **Numerical Features Distribution** - Compare distributions between two target classes\n",
    "3. **Key Insights** - Summarize findings from visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA VISUALISATION: Feature Relationships with Target Variable\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1af23",
   "metadata": {},
   "source": [
    "#### Visualisation 1: Key Categorical Features vs Job Change Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33060ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key categorical features for visualization\n",
    "key_cat_features = ['relevent_experience', 'company_size', 'company_type', 'education_level']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Job Change Rate by Key Categorical Features', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "for idx, feature in enumerate(key_cat_features):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Calculate target rate for each category\n",
    "    crosstab = pd.crosstab(df[feature], df['target'])\n",
    "    target_rate = (crosstab[1.0] / crosstab.sum(axis=1) * 100).sort_values(ascending=False)\n",
    "    \n",
    "    # Create bar plot\n",
    "    colors = plt.cm.RdYlGn_r(target_rate / 100)\n",
    "    bars = ax.barh(range(len(target_rate)), target_rate.values, color=colors, edgecolor='black', linewidth=1.2)\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_yticks(range(len(target_rate)))\n",
    "    ax.set_yticklabels(target_rate.index, fontsize=10)\n",
    "    ax.set_xlabel('Job Change Rate (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{feature}', fontsize=12, fontweight='bold')\n",
    "    ax.axvline(df['target'].mean() * 100, color='red', linestyle='--', linewidth=2, label='Overall Average')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (v, count) in enumerate(zip(target_rate.values, crosstab.sum(axis=1)[target_rate.index])):\n",
    "        ax.text(v + 1, i, f'{v:.1f}% (n={count:,})', va='center', fontsize=9)\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_xlim(0, max(target_rate.values) * 1.15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. Relevant Experience: Candidates WITH relevant experience have LOWER job change rates\")\n",
    "print(\"2. Company Size: Smaller companies (<10) show higher job change tendency\")\n",
    "print(\"3. Company Type: Pvt Ltd companies have highest retention (lowest change rate)\")\n",
    "print(\"4. Education Level: Graduate level shows balanced job change behavior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c4dec1",
   "metadata": {},
   "source": [
    "#### Visualisation 2: Experience Level Distribution by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd607dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize experience distribution for both target classes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Experience Distribution: Job Changers vs Non-Changers', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Convert experience to numeric for plotting\n",
    "exp_mapping = {\n",
    "    '<1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,\n",
    "    '6': 6, '7': 7, '8': 8, '9': 9, '10': 10,\n",
    "    '11': 11, '12': 12, '13': 13, '14': 14, '15': 15,\n",
    "    '16': 16, '17': 17, '18': 18, '19': 19, '20': 20, '>20': 21\n",
    "}\n",
    "\n",
    "df_temp = df.copy()\n",
    "df_temp['experience_numeric'] = df_temp['experience'].map(exp_mapping)\n",
    "\n",
    "# Plot 1: Histogram comparison\n",
    "for target_val, color, label in [(0, '#3498db', 'Not Looking for Change'), \n",
    "                                   (1, '#e74c3c', 'Looking for Change')]:\n",
    "    data = df_temp[df_temp['target'] == target_val]['experience_numeric'].dropna()\n",
    "    axes[0].hist(data, bins=22, alpha=0.6, label=label, color=color, edgecolor='black')\n",
    "\n",
    "axes[0].set_xlabel('Years of Experience', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Experience Distribution Comparison', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Box plot comparison\n",
    "df_temp.boxplot(column='experience_numeric', by='target', ax=axes[1], patch_artist=True)\n",
    "axes[1].set_xlabel('Target (0=Not Looking, 1=Looking)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Years of Experience', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Experience Distribution by Target', fontsize=13, fontweight='bold')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Average experience (Not looking for change): {df_temp[df_temp['target']==0]['experience_numeric'].mean():.2f} years\")\n",
    "print(f\"Average experience (Looking for change):     {df_temp[df_temp['target']==1]['experience_numeric'].mean():.2f} years\")\n",
    "print(\"Job changers tend to have slightly LOWER average experience\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a928c",
   "metadata": {},
   "source": [
    "#### Visualisation 3: Training Hours and City Development Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Numerical Features: Training Hours & City Development Index', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Training Hours by Target\n",
    "for target_val, color, label in [(0, '#3498db', 'Not Looking (0)'), \n",
    "                                   (1, '#e74c3c', 'Looking (1)')]:\n",
    "    data = df[df['target'] == target_val]['training_hours']\n",
    "    axes[0].hist(data, bins=30, alpha=0.6, label=label, color=color, edgecolor='black')\n",
    "\n",
    "axes[0].set_xlabel('Training Hours', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Training Hours Distribution by Target', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].axvline(df[df['target']==0]['training_hours'].mean(), color='#3498db', linestyle='--', linewidth=2, label='Mean (0)')\n",
    "axes[0].axvline(df[df['target']==1]['training_hours'].mean(), color='#e74c3c', linestyle='--', linewidth=2, label='Mean (1)')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: City Development Index by Target\n",
    "df.boxplot(column='city_development_index', by='target', ax=axes[1], patch_artist=True)\n",
    "axes[1].set_xlabel('Target (0=Not Looking, 1=Looking)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('City Development Index', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('City Development Index by Target', fontsize=13, fontweight='bold')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Average training hours (Not looking): {df[df['target']==0]['training_hours'].mean():.1f} hours\")\n",
    "print(f\"Average training hours (Looking):     {df[df['target']==1]['training_hours'].mean():.1f} hours\")\n",
    "print(f\"Average CDI (Not looking): {df[df['target']==0]['city_development_index'].mean():.3f}\")\n",
    "print(f\"Average CDI (Looking):     {df[df['target']==1]['city_development_index'].mean():.3f}\")\n",
    "print(\"\\nCandidates in MORE developed cities are LESS likely to change jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02843f68",
   "metadata": {},
   "source": [
    "#### Summary of Visualisation Insights\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Relevant Experience Impact**\n",
    "   - Candidates WITHOUT relevant experience are MORE likely to seek job changes\n",
    "   - This suggests career dissatisfaction or seeking better fit\n",
    "\n",
    "2. **Company Size Effect**\n",
    "   - Smaller companies (<10 employees) have higher turnover rates\n",
    "   - Larger companies (1000+) show better retention\n",
    "\n",
    "3. **Experience Level Paradox**\n",
    "   - Job changers have slightly LOWER average experience\n",
    "   - Mid-career professionals (5-10 years) show highest mobility\n",
    "\n",
    "4. **City Development Factor**\n",
    "   - Candidates in less developed cities are MORE likely to change jobs\n",
    "   - Economic opportunities may drive this pattern\n",
    "\n",
    "5. **Training Hours**\n",
    "   - Similar training hours across both groups\n",
    "   - Training alone doesn't predict job change behavior\n",
    "\n",
    "**Implications for Modeling:**\n",
    "- `relevent_experience`, `company_size`, and `city_development_index` are likely strong predictors\n",
    "- `experience` shows non-linear relationship (requires careful feature engineering)\n",
    "- `training_hours` may be less predictive (but still worth including)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8fc5a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  3. Data Cleaning & Feature Engineering Strategy\n",
    "\n",
    "Based on the comprehensive data analysis above, here is the detailed processing strategy for each of the 14 features:\n",
    "\n",
    "###  3.1 Strategy Overview Table\n",
    "\n",
    "| # | Feature | Type | Action | Priority | Reason |\n",
    "|---|---------|------|--------|----------|--------|\n",
    "| 1 | `enrollee_id` | ID | **DELETE** | ðŸ”´ High | No predictive value - just an identifier |\n",
    "| 2 | `city` | Categorical (123 values) | **Target Encoding** | ðŸŸ¡ Medium | Too many categories for One-Hot |\n",
    "| 3 | `city_development_index` | Numerical | **Keep as-is** | ðŸŸ¢ Low | Already numeric, no missing values |\n",
    "| 4 | `gender` | Categorical (3 values) | **Fill Missing + One-Hot** | ðŸŸ¡ Medium | 23% missing, create \"Unknown\" category |\n",
    "| 5 | `relevent_experience` | Binary | **Label Encoding** | ðŸŸ¢ Low | No missing, convert to 0/1 |\n",
    "| 6 | `enrolled_university` | Categorical (3 values) | **Fill Missing + One-Hot** | ðŸŸ¢ Low | 2% missing, 3 clear categories |\n",
    "| 7 | `education_level` | Ordinal (5 values) | **Ordinal Encoding** | ðŸŸ¡ Medium | 2% missing, has natural order |\n",
    "| 8 | `major_discipline` | Categorical (6 values) | **Fill Missing + One-Hot** | ðŸŸ¡ Medium | 15% missing, may correlate with education |\n",
    "| 9 | `experience` | Ordinal (22 values) | **Ordinal Encoding** | ðŸ”´ High | Convert to numeric years (e.g., \"<1\"â†’0, \">20\"â†’21) |\n",
    "| 10 | `company_size` | Ordinal (8 values) | **Fix Format + Ordinal** | ðŸ”´ High | 31% missing, FIX \"10/49\" â†’ \"10-49\" |\n",
    "| 11 | `company_type` | Categorical (6 values) | **Fill Missing + One-Hot** | ðŸŸ¡ Medium | 32% missing, create \"Unknown\" |\n",
    "| 12 | `last_new_job` | Ordinal (6 values) | **Ordinal Encoding** | ðŸŸ¢ Low | 2% missing, convert to numeric |\n",
    "| 13 | `training_hours` | Numerical | **Keep as-is** | ðŸŸ¢ Low | Already numeric, no missing values |\n",
    "| 14 | `target` | Binary | **Keep as-is** | N/A | Target variable - no transformation needed |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6ee55",
   "metadata": {},
   "source": [
    "### 3.2 Data Clean and Base Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68762c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the original dataframe for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(f\"Original dataset shape: {df_clean.shape}\")\n",
    "print(f\"Starting data cleaning process...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de077cc9",
   "metadata": {},
   "source": [
    "#### 1. `enrollee_id`\n",
    "Delete the column `enrollee_id` because it is not interesting for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: enrollee_id\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 1: enrollee_id\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['enrollee_id'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Delete the column (no predictive value)\n",
    "df_clean = df_clean.drop('enrollee_id', axis=1)\n",
    "\n",
    "print(f\"\\nFeature 1 processed: enrollee_id\")\n",
    "print(f\"   Action: Deleted (identifier column)\")\n",
    "print(f\"   New shape: {df_clean.shape}\")\n",
    "print(f\"   Columns remaining: {df_clean.shape[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364fe2eb",
   "metadata": {},
   "source": [
    "#### 2. `company_size`\n",
    "**Action:** Fix format error ('10/49'â†’'10-49'), create missing indicator, fill with median, ordinal encoding (0-7)  \n",
    "**Reason:** 31% missing + format issue; ordinal relationship exists (company scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: company_size\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 2: company_size\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['company_size'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Step 1: Fix formatting error\n",
    "print(\"\\nStep 1: Fix formatting error '10/49' -> '10-49'\")\n",
    "df_clean['company_size'] = df_clean['company_size'].replace('10/49', '10-49')\n",
    "print(f\"   Fixed {df_clean['company_size'].value_counts().get('10-49', 0):,} instances\")\n",
    "\n",
    "# Step 2: Create missing indicator\n",
    "print(\"\\nStep 2: Create missing indicator feature\")\n",
    "df_clean['company_size_missing'] = df_clean['company_size'].isna().astype(int)\n",
    "print(f\"   Created 'company_size_missing' (1=missing, 0=known)\")\n",
    "\n",
    "# Step 3: Fill missing with median category\n",
    "print(\"\\nStep 3: Fill missing with median category\")\n",
    "median_category = '50-99'\n",
    "df_clean['company_size'] = df_clean['company_size'].fillna(median_category)\n",
    "print(f\"   Filled {missing_count:,} missing values with '{median_category}'\")\n",
    "print(f\"   Missing after: {df_clean['company_size'].isna().sum()}\")\n",
    "\n",
    "# Step 4: Ordinal encoding\n",
    "print(\"\\nStep 4: Ordinal encoding (small to large)\")\n",
    "size_order = {\n",
    "    '<10': 0, '10-49': 1, '50-99': 2, '100-500': 3,\n",
    "    '500-999': 4, '1000-4999': 5, '5000-9999': 6, '10000+': 7\n",
    "}\n",
    "df_clean['company_size'] = df_clean['company_size'].map(size_order)\n",
    "\n",
    "print(\"   Encoding mapping:\")\n",
    "for key, value in size_order.items():\n",
    "    count = (df_clean['company_size'] == value).sum()\n",
    "    print(f\"      {key:12s} -> {value}  ({count:,} samples)\")\n",
    "\n",
    "print(f\"\\nFeature 2 processed: company_size + company_size_missing\")\n",
    "print(f\"   company_size: Type={df_clean['company_size'].dtype}, Range=[{df_clean['company_size'].min()}, {df_clean['company_size'].max()}]\")\n",
    "print(f\"   company_size_missing: {df_clean['company_size_missing'].value_counts().to_dict()}\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a8048",
   "metadata": {},
   "source": [
    "#### 3. `company_type`\n",
    "**Action:** Fill missing with 'Unknown', One-Hot encoding  \n",
    "**Reason:** 32% missing; 6 nominal categories (no natural order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f0ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: company_type\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 3: company_type\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['company_type'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Step 1: Fill missing values\n",
    "print(\"\\nStep 1: Fill missing values with 'Unknown'\")\n",
    "df_clean['company_type'] = df_clean['company_type'].fillna('Unknown')\n",
    "print(f\"   Filled {missing_count:,} missing values with 'Unknown'\")\n",
    "print(f\"   Missing after: {df_clean['company_type'].isna().sum()}\")\n",
    "\n",
    "# Step 2: One-Hot encoding\n",
    "print(\"\\nStep 2: One-Hot encoding\")\n",
    "print(f\"   Categories: {sorted(df_clean['company_type'].unique())}\")\n",
    "\n",
    "company_type_dummies = pd.get_dummies(df_clean['company_type'], prefix='company_type', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, company_type_dummies], axis=1)\n",
    "df_clean = df_clean.drop('company_type', axis=1)\n",
    "\n",
    "print(f\"   Created {len(company_type_dummies.columns)} binary columns:\")\n",
    "for col in sorted(company_type_dummies.columns):\n",
    "    count = df_clean[col].sum()\n",
    "    print(f\"      {col:35s}: {count:,} samples\")\n",
    "\n",
    "print(f\"\\nFeature 3 processed: company_type\")\n",
    "print(f\"   New columns added: {len(company_type_dummies.columns)}\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1eb25",
   "metadata": {},
   "source": [
    "#### 4. `gender`\n",
    "**Action:** Fill missing with 'Unknown', One-Hot encoding  \n",
    "**Reason:** 23% missing; 3 nominal categories (Male/Female/Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b54b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 4: gender\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 4: gender\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['gender'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Step 1: Fill missing values\n",
    "print(\"\\nStep 1: Fill missing values with 'Unknown'\")\n",
    "df_clean['gender'] = df_clean['gender'].fillna('Unknown')\n",
    "print(f\"   Filled {missing_count:,} missing values with 'Unknown'\")\n",
    "print(f\"   Missing after: {df_clean['gender'].isna().sum()}\")\n",
    "\n",
    "# Step 2: One-Hot encoding\n",
    "print(\"\\nStep 2: One-Hot encoding\")\n",
    "gender_dummies = pd.get_dummies(df_clean['gender'], prefix='gender', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, gender_dummies], axis=1)\n",
    "df_clean = df_clean.drop('gender', axis=1)\n",
    "\n",
    "print(f\"   Created {len(gender_dummies.columns)} binary columns:\")\n",
    "for col in sorted(gender_dummies.columns):\n",
    "    count = df_clean[col].sum()\n",
    "    print(f\"      {col:35s}: {count:,} samples\")\n",
    "\n",
    "print(f\"\\nFeature 4 processed: gender\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0acf3b",
   "metadata": {},
   "source": [
    "#### 5. `major_discipline`\n",
    "**Action:** Fill missing with 'Unknown', One-Hot encoding  \n",
    "**Reason:** 15% missing; 6 nominal categories (STEM, Business, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9528fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 5: major_discipline\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 5: major_discipline\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['major_discipline'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Step 1: Fill missing values\n",
    "print(\"\\nStep 1: Fill missing values with 'Unknown'\")\n",
    "df_clean['major_discipline'] = df_clean['major_discipline'].fillna('Unknown')\n",
    "print(f\"   Filled {missing_count:,} missing values with 'Unknown'\")\n",
    "print(f\"   Missing after: {df_clean['major_discipline'].isna().sum()}\")\n",
    "\n",
    "# Step 2: One-Hot encoding\n",
    "print(\"\\nStep 2: One-Hot encoding\")\n",
    "major_dummies = pd.get_dummies(df_clean['major_discipline'], prefix='major', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, major_dummies], axis=1)\n",
    "df_clean = df_clean.drop('major_discipline', axis=1)\n",
    "\n",
    "print(f\"   Created {len(major_dummies.columns)} binary columns:\")\n",
    "for col in sorted(major_dummies.columns):\n",
    "    count = df_clean[col].sum()\n",
    "    print(f\"      {col:35s}: {count:,} samples\")\n",
    "\n",
    "print(f\"\\nFeature 5 processed: major_discipline\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14bb2f5",
   "metadata": {},
   "source": [
    "#### 6. `experience`\n",
    "**Action:** Fill missing with median, ordinal encoding ('<1'â†’0, '20'â†’20, '>20'â†’21)  \n",
    "**Reason:** Few missing values; clear ordinal relationship (years of experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 6: experience\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 6: experience\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['experience'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Define ordinal mapping\n",
    "exp_mapping = {\n",
    "    '<1': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,\n",
    "    '6': 6, '7': 7, '8': 8, '9': 9, '10': 10,\n",
    "    '11': 11, '12': 12, '13': 13, '14': 14, '15': 15,\n",
    "    '16': 16, '17': 17, '18': 18, '19': 19, '20': 20, '>20': 21\n",
    "}\n",
    "\n",
    "# Step 1: Fill missing with median\n",
    "print(\"\\nStep 1: Fill missing with median\")\n",
    "temp_numeric = df_clean['experience'].dropna().map(exp_mapping)\n",
    "median_value = temp_numeric.median()\n",
    "median_key = min(exp_mapping.items(), key=lambda x: abs(x[1] - median_value))[0]\n",
    "df_clean['experience'] = df_clean['experience'].fillna(median_key)\n",
    "print(f\"   Filled {missing_count:,} missing values with median '{median_key}' (value={exp_mapping[median_key]})\")\n",
    "\n",
    "# Step 2: Ordinal encoding\n",
    "print(\"\\nStep 2: Ordinal encoding\")\n",
    "df_clean['experience'] = df_clean['experience'].map(exp_mapping)\n",
    "print(f\"   Encoded: '<1'->0, '1'->1, ..., '>20'->21\")\n",
    "\n",
    "print(f\"\\nFeature 6 processed: experience\")\n",
    "print(f\"   Type: {df_clean['experience'].dtype}, Range: [{df_clean['experience'].min()}, {df_clean['experience'].max()}] years\")\n",
    "print(f\"   Missing after: {df_clean['experience'].isna().sum()}\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb66db8",
   "metadata": {},
   "source": [
    "#### 7. `education_level`\n",
    "**Action:** Fill missing with mode, ordinal encoding (Primaryâ†’1 to PhDâ†’5)  \n",
    "**Reason:** 2% missing; clear educational hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2418968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 7: education_level\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 7: education_level\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['education_level'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Step 1: Fill missing with mode\n",
    "print(\"\\nStep 1: Fill missing with mode\")\n",
    "mode_value = df_clean['education_level'].mode()[0]\n",
    "df_clean['education_level'] = df_clean['education_level'].fillna(mode_value)\n",
    "print(f\"   Filled {missing_count:,} missing values with mode '{mode_value}'\")\n",
    "\n",
    "# Step 2: Ordinal encoding\n",
    "print(\"\\nStep 2: Ordinal encoding (educational hierarchy)\")\n",
    "edu_mapping = {\n",
    "    'Primary School': 1,\n",
    "    'High School': 2,\n",
    "    'Graduate': 3,\n",
    "    'Masters': 4,\n",
    "    'Phd': 5\n",
    "}\n",
    "df_clean['education_level'] = df_clean['education_level'].map(edu_mapping)\n",
    "print(f\"   Encoded: Primary School->1, High School->2, Graduate->3, Masters->4, PhD->5\")\n",
    "\n",
    "print(f\"\\nFeature 7 processed: education_level\")\n",
    "print(f\"   Type: {df_clean['education_level'].dtype}, Range: [{df_clean['education_level'].min()}, {df_clean['education_level'].max()}]\")\n",
    "print(f\"   Missing after: {df_clean['education_level'].isna().sum()}\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c317da",
   "metadata": {},
   "source": [
    "#### 8. `enrolled_university`\n",
    "**Action:** Fill missing with 'no_enrollment', One-Hot encoding  \n",
    "**Reason:** 2% missing; 3 nominal categories (enrollment status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710498d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 8: enrolled_university\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 8: enrolled_university\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['enrolled_university'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Step 1: Fill missing values\n",
    "print(\"\\nStep 1: Fill missing values with 'no_enrollment'\")\n",
    "df_clean['enrolled_university'] = df_clean['enrolled_university'].fillna('no_enrollment')\n",
    "print(f\"   Missing after: {df_clean['enrolled_university'].isna().sum()}\")\n",
    "\n",
    "# Step 2: One-Hot encoding\n",
    "print(\"\\nStep 2: One-Hot encoding\")\n",
    "enrolled_dummies = pd.get_dummies(df_clean['enrolled_university'], prefix='enrolled', drop_first=False)\n",
    "df_clean = pd.concat([df_clean, enrolled_dummies], axis=1)\n",
    "df_clean = df_clean.drop('enrolled_university', axis=1)\n",
    "\n",
    "print(f\"   Created {len(enrolled_dummies.columns)} binary columns:\")\n",
    "for col in sorted(enrolled_dummies.columns):\n",
    "    count = df_clean[col].sum()\n",
    "    print(f\"      {col:35s}: {count:,} samples\")\n",
    "\n",
    "print(f\"\\nFeature 8 processed: enrolled_university\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d400a9b",
   "metadata": {},
   "source": [
    "#### 9. `relevent_experience`\n",
    "**Action:** Binary encoding (Hasâ†’1, Noâ†’0)  \n",
    "**Reason:** No missing values; binary feature with clear yes/no distinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6124f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 9: relevent_experience\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 9: relevent_experience\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['relevent_experience'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Binary encoding\n",
    "print(\"\\nStep 1: Binary encoding\")\n",
    "df_clean['relevent_experience'] = df_clean['relevent_experience'].map({\n",
    "    'Has relevent experience': 1,\n",
    "    'No relevent experience': 0\n",
    "})\n",
    "print(f\"   Encoded: 'Has relevent experience'->1, 'No relevent experience'->0\")\n",
    "\n",
    "print(f\"\\nFeature 9 processed: relevent_experience\")\n",
    "print(f\"   Type: {df_clean['relevent_experience'].dtype}\")\n",
    "print(f\"   Distribution: {df_clean['relevent_experience'].value_counts().to_dict()}\")\n",
    "print(f\"   Missing after: {df_clean['relevent_experience'].isna().sum()}\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fe80a7",
   "metadata": {},
   "source": [
    "#### 10. `last_new_job`\n",
    "**Action:** Fill missing with mode, ordinal encoding ('never'â†’0 to '>4'â†’5)  \n",
    "**Reason:** 2% missing; ordinal relationship (recency of job change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31196115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 10: last_new_job\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 10: last_new_job\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['last_new_job'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "\n",
    "# Step 1: Fill missing with mode\n",
    "print(\"\\nStep 1: Fill missing with mode\")\n",
    "mode_value = df_clean['last_new_job'].mode()[0]\n",
    "df_clean['last_new_job'] = df_clean['last_new_job'].fillna(mode_value)\n",
    "print(f\"   Filled {missing_count:,} missing values with mode '{mode_value}'\")\n",
    "\n",
    "# Step 2: Ordinal encoding\n",
    "print(\"\\nStep 2: Ordinal encoding (job change recency)\")\n",
    "job_mapping = {'never': 0, '1': 1, '2': 2, '3': 3, '4': 4, '>4': 5}\n",
    "df_clean['last_new_job'] = df_clean['last_new_job'].map(job_mapping)\n",
    "print(f\"   Encoded: 'never'->0, '1'->1, '2'->2, '3'->3, '4'->4, '>4'->5\")\n",
    "\n",
    "print(f\"\\nFeature 10 processed: last_new_job\")\n",
    "print(f\"   Type: {df_clean['last_new_job'].dtype}, Range: [{df_clean['last_new_job'].min()}, {df_clean['last_new_job'].max()}]\")\n",
    "print(f\"   Missing after: {df_clean['last_new_job'].isna().sum()}\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861987d",
   "metadata": {},
   "source": [
    "#### 11. `city`\n",
    "**Action:** Target encoding after dataset split (to prevent data leakage)  \n",
    "**Reason:** High cardinality (123 unique values); avoid curse of dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21cb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 11: city\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Feature 11: city\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_count = df_clean['city'].isna().sum()\n",
    "print(f\"\\nMissing before: {missing_count} ({missing_count/len(df_clean)*100:.2f}%)\")\n",
    "print(f\"Unique cities: {df_clean['city'].nunique()}\")\n",
    "\n",
    "print(\"\\nNote: Target encoding will be applied AFTER dataset split\")\n",
    "print(\"   Reason: Prevent data leakage (target info must not leak from train to test)\")\n",
    "print(\"   High cardinality (123 cities) - unsuitable for One-Hot encoding\")\n",
    "\n",
    "print(f\"\\nFeature 11 prepared: city (encoding deferred)\")\n",
    "print(f\"   Will encode after train/validation/test split\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a818fd",
   "metadata": {},
   "source": [
    "#### 12-13. `city_development_index` & `training_hours`\n",
    "**Action:** Keep as-is (no transformation needed)  \n",
    "**Reason:** Already numeric, no missing values, ready for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features 12-13: city_development_index & training_hours\n",
    "print(\"=\"*70)\n",
    "print(\"Processing Features 12-13: Numeric Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Feature 12: city_development_index\n",
    "missing_count_cdi = df_clean['city_development_index'].isna().sum()\n",
    "print(f\"\\nFeature 12: city_development_index\")\n",
    "print(f\"   Missing: {missing_count_cdi} ({missing_count_cdi/len(df_clean)*100:.2f}%)\")\n",
    "print(f\"   Type: {df_clean['city_development_index'].dtype}\")\n",
    "print(f\"   Range: [{df_clean['city_development_index'].min():.3f}, {df_clean['city_development_index'].max():.3f}]\")\n",
    "print(f\"   Already numeric, no transformation needed\")\n",
    "\n",
    "# Feature 13: training_hours\n",
    "missing_count_th = df_clean['training_hours'].isna().sum()\n",
    "print(f\"\\nFeature 13: training_hours\")\n",
    "print(f\"   Missing: {missing_count_th} ({missing_count_th/len(df_clean)*100:.2f}%)\")\n",
    "print(f\"   Type: {df_clean['training_hours'].dtype}\")\n",
    "print(f\"   Range: [{df_clean['training_hours'].min()}, {df_clean['training_hours'].max()}] hours\")\n",
    "print(f\"   Already numeric, no transformation needed\")\n",
    "\n",
    "print(f\"\\nFeatures 12-13 processed: city_development_index & training_hours\")\n",
    "print(f\"   Shape: {df_clean.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: Check cleaned data quality\n",
    "print(\"=\"*80)\n",
    "print(\"DATA CLEANING VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Shape comparison\n",
    "print(\"\\n1. Dataset Shape:\")\n",
    "print(f\"   Original: {df.shape}\")\n",
    "print(f\"   Cleaned:  {df_clean.shape}\")\n",
    "print(f\"   Rows preserved: {df_clean.shape[0]} (100%)\")\n",
    "print(f\"   Columns changed: {df.shape[1]} â†’ {df_clean.shape[1]} (due to One-Hot encoding)\")\n",
    "\n",
    "# 2. Missing values check\n",
    "print(\"\\n2. Missing Values:\")\n",
    "missing_after = df_clean.isnull().sum().sum()\n",
    "if missing_after == 0:\n",
    "    print(f\"   No missing values! All {df_clean.shape[0] * df_clean.shape[1]:,} cells are filled\")\n",
    "else:\n",
    "    print(f\"   WARNING: {missing_after} missing values found!\")\n",
    "    print(df_clean.isnull().sum()[df_clean.isnull().sum() > 0])\n",
    "\n",
    "# 3. Data types check\n",
    "print(\"\\n3. Data Types:\")\n",
    "dtypes_summary = df_clean.dtypes.value_counts()\n",
    "print(f\"   {dtypes_summary.to_dict()}\")\n",
    "non_numeric = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "if len(non_numeric) == 0:\n",
    "    print(f\"   All features are numeric (ready for modeling)\")\n",
    "else:\n",
    "    print(f\"   Non-numeric columns found: {non_numeric}\")\n",
    "\n",
    "# 4. Feature list\n",
    "print(\"\\n4. Final Feature List:\")\n",
    "feature_cols = [col for col in df_clean.columns if col != 'target']\n",
    "print(f\"   Total features: {len(feature_cols)}\")\n",
    "print(f\"   Features: {', '.join(sorted(feature_cols)[:10])}...\")\n",
    "\n",
    "# 5. Display sample\n",
    "print(\"\\n5. Sample of Cleaned Data (first 3 rows):\")\n",
    "print(\"=\"*80)\n",
    "display(df_clean.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA CLEANING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cfbaf2",
   "metadata": {},
   "source": [
    "## 4. Dataset Split & Target Encoding (5-Fold Cross-Validation Strategy)\n",
    "\n",
    "**Overview:**\n",
    "This section implements a 5-Fold Stratified Cross-Validation strategy to maximize data utilization and improve model evaluation reliability.\n",
    "\n",
    "**Key Steps:**\n",
    "1. **Separate test set (20%)** - Hold out for final evaluation\n",
    "2. **Setup 5-Fold CV on remaining 80%** - For model training and validation\n",
    "3. **Target encode `city` feature** - Handle high cardinality without data leakage\n",
    "4. **Verify data quality** - Ensure all features are numeric and ready\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52894146",
   "metadata": {},
   "source": [
    "### 4.1 Prepare Features and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43153f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df_clean.drop('target', axis=1)\n",
    "y = df_clean['target'].astype(int)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Dataset Preparation\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Feature matrix X: {X.shape}\")\n",
    "print(f\"Target variable y: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Class 0 (Not looking for change): {(y==0).sum():,} ({(y==0).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"  Class 1 (Looking for change):     {(y==1).sum():,} ({(y==1).sum()/len(y)*100:.2f}%)\")\n",
    "print(f\"  Class ratio: {(y==0).sum()/(y==1).sum():.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207ed13c",
   "metadata": {},
   "source": [
    "### 4.2 Dataset Split Strategy: 5-Fold Stratified Cross-Validation\n",
    "\n",
    "**Why 5-Fold CV?**\n",
    "- **Better data utilization**: 80% used for training (vs 60% in 3-way split)\n",
    "- **More reliable evaluation**: Each sample serves as validation once, averaged over 5 folds\n",
    "- **Reduced variance**: Multiple validation results -> more stable performance estimate\n",
    "\n",
    "**Split Strategy:**\n",
    "1. **Test set (20%)**: Hold out completely, only used for final evaluation\n",
    "2. **Train+Validation (80%)**: Split into 5 folds for cross-validation\n",
    "   - Each fold: 4 parts training (64%) + 1 part validation (16%)\n",
    "   - Repeat 5 times, every sample gets validated once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Separate test set (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,           # 20% for test set\n",
    "    stratify=y,               # Stratified sampling to preserve class ratio\n",
    "    random_state=22207256           # Fixed seed for reproducibility\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Step 1: Test Set Separation\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train+Validation set: {X_train_val.shape[0]:,} samples ({X_train_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Test set:             {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Verify class distribution in test set\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(f\"  Class 0: {(y_test==0).sum():,} ({(y_test==0).sum()/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Class 1: {(y_test==1).sum():,} ({(y_test==1).sum()/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Ratio: {(y_test==0).sum()/(y_test==1).sum():.2f}:1\")\n",
    "\n",
    "# Step 2: Setup 5-Fold Stratified Cross-Validation on Train+Val set\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Step 2: Setup 5-Fold Stratified Cross-Validation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=22307256)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Number of folds: 5\")\n",
    "print(f\"  Total samples for CV: {X_train_val.shape[0]:,}\")\n",
    "print(f\"  Samples per fold (validation): ~{X_train_val.shape[0]//5:,} ({100/5:.1f}%)\")\n",
    "print(f\"  Samples per fold (training): ~{X_train_val.shape[0]*4//5:,} ({100*4/5:.1f}%)\")\n",
    "\n",
    "# Verify fold quality\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"Fold Quality Verification:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Fold':<8} {'Train Samples':<15} {'Val Samples':<15} {'Class 0 (Val)':<15} {'Class 1 (Val)':<15} {'Ratio':<10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_val, y_train_val), 1):\n",
    "    y_val_fold = y_train_val.iloc[val_idx]\n",
    "    class_0 = (y_val_fold == 0).sum()\n",
    "    class_1 = (y_val_fold == 1).sum()\n",
    "    ratio = class_0 / class_1 if class_1 > 0 else 0\n",
    "    \n",
    "    print(f\"Fold {fold:<3} {len(train_idx):<15,} {len(val_idx):<15,} {class_0:<7,} ({class_0/len(y_val_fold)*100:5.2f}%)  {class_1:<7,} ({class_1/len(y_val_fold)*100:5.2f}%)  {ratio:.2f}:1\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dataset Split Summary\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train+Validation: {X_train_val.shape[0]:,} samples ({X_train_val.shape[0]/len(X)*100:.1f}%) - Used for 5-Fold CV\")\n",
    "print(f\"Test set:         {X_test.shape[0]:,} samples ({X_test.shape[0]/len(X)*100:.1f}%) - Held out for final evaluation\")\n",
    "print(f\"Total:            {len(X):,} samples (100%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aced7d3",
   "metadata": {},
   "source": [
    "### 4.3 Target Encoding for `city`\n",
    "\n",
    "**Why Target Encoding?**\n",
    "- `city` has 123 unique values (high cardinality)\n",
    "- One-Hot encoding would create 123 columns (curse of dimensionality)\n",
    "- Target encoding maps each city to its average target value\n",
    "\n",
    "**Preventing Data Leakage:**\n",
    "- Encoder fitted ONLY on training data\n",
    "- Then applied to validation and test sets\n",
    "- Cross-validation built into TargetEncoder (cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Feature 11: city\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize Target Encoder\n",
    "target_encoder = TargetEncoder(\n",
    "    cv=5,                    # 5-fold cross-validation to prevent overfitting\n",
    "    smooth='auto',           # Automatic smoothing for low-frequency cities\n",
    "    target_type='binary'     # Binary classification target\n",
    ")\n",
    "\n",
    "# Step 1: Fit encoder on Train+Validation set\n",
    "print(\"\\nStep 1: Fit encoder on Train+Validation set\")\n",
    "print(f\"   Unique cities: {X_train_val['city'].nunique()}\")\n",
    "print(f\"   Total samples: {len(X_train_val):,}\")\n",
    "\n",
    "target_encoder.fit(X_train_val[['city']], y_train_val)\n",
    "print(\"   Encoder trained successfully\")\n",
    "\n",
    "# Step 2: Transform Train+Validation set\n",
    "print(\"\\nStep 2: Encode Train+Validation set\")\n",
    "X_train_val_encoded = X_train_val.copy()\n",
    "X_train_val_encoded['city_encoded'] = target_encoder.transform(X_train_val[['city']])\n",
    "X_train_val_encoded = X_train_val_encoded.drop('city', axis=1)\n",
    "print(f\"   Train+Val set encoded\")\n",
    "print(f\"   Encoding range: [{X_train_val_encoded['city_encoded'].min():.4f}, {X_train_val_encoded['city_encoded'].max():.4f}]\")\n",
    "\n",
    "# Step 3: Transform Test set\n",
    "print(\"\\nStep 3: Encode Test set (using Train+Val encoding)\")\n",
    "X_test_encoded = X_test.copy()\n",
    "X_test_encoded['city_encoded'] = target_encoder.transform(X_test[['city']])\n",
    "X_test_encoded = X_test_encoded.drop('city', axis=1)\n",
    "print(f\"   Test set encoded\")\n",
    "print(f\"   Test set cities: {X_test['city'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Target Encoding Complete\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train+Validation set: {X_train_val_encoded.shape}\")\n",
    "print(f\"Test set:             {X_test_encoded.shape}\")\n",
    "print(f\"\\nAll features are now numeric and ready for 5-Fold Cross-Validation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99dcf20",
   "metadata": {},
   "source": [
    "### 4.4 Final Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96216e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset summary\n",
    "print(\"=\"*80)\n",
    "print(\"Final Dataset Summary\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Dataset Shapes:\")\n",
    "print(f\"   Train+Validation: X_train_val_encoded {X_train_val_encoded.shape}, y_train_val {y_train_val.shape}\")\n",
    "print(f\"   Test set:         X_test_encoded      {X_test_encoded.shape}, y_test      {y_test.shape}\")\n",
    "\n",
    "print(\"\\n2. Number of Features:\")\n",
    "print(f\"   Total features: {X_train_val_encoded.shape[1]}\")\n",
    "\n",
    "print(\"\\n3. Missing Values Check:\")\n",
    "print(f\"   Train+Val missing: {X_train_val_encoded.isnull().sum().sum()}\")\n",
    "print(f\"   Test missing:      {X_test_encoded.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\n4. Feature List (all features):\")\n",
    "feature_cols = X_train_val_encoded.columns.tolist()\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n5. Sample Data (Train+Val first 3 rows):\")\n",
    "display(X_train_val_encoded.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Dataset Preparation Complete!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Ready for 5-Fold Cross-Validation with {X_train_val_encoded.shape[0]:,} samples\")\n",
    "print(f\"Test set ({X_test_encoded.shape[0]:,} samples) reserved for final evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435122e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Attribute Selection\n",
    "\n",
    "**Why After Data Split?**\n",
    "\n",
    "To prevent data leakage, we perform feature selection **ONLY on the training+validation set** (80% data). The test set (20%) remains completely isolated and will not influence our feature selection decisions. This ensures unbiased final evaluation.\n",
    "\n",
    "**Our Strategy:**\n",
    "\n",
    "1. **Feature Importance Analysis** - Use Random Forest to rank feature importance\n",
    "2. **Visualize Importances** - Identify which features contribute most to predictions\n",
    "3. **Correlation Analysis** - Check for multicollinearity among features\n",
    "4. **Selection Experiment** - Compare performance with all features vs. selected features\n",
    "5. **Final Decision** - Decide which features to keep for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d52852",
   "metadata": {},
   "source": [
    "### 5.1 Feature Importance Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc151ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Train a Random Forest on training+validation set to get feature importances\n",
    "print(\"\\nStep 1: Training Random Forest for feature importance analysis\")\n",
    "print(f\"   Using {X_train_val_encoded.shape[0]:,} samples\")\n",
    "print(f\"   Total features: {X_train_val_encoded.shape[1]}\")\n",
    "\n",
    "rf_importance = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=22207256,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_importance.fit(X_train_val_encoded, y_train_val)\n",
    "print(\"   Random Forest trained successfully\")\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train_val_encoded.columns,\n",
    "    'Importance': rf_importance.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nStep 2: Feature Importance Ranking\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Rank':<6} {'Feature':<40} {'Importance':<12} {'Cumulative %':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "cumulative_importance = 0\n",
    "for idx, row in feature_importances.iterrows():\n",
    "    cumulative_importance += row['Importance']\n",
    "    print(f\"{feature_importances.index.get_loc(idx)+1:<6} {row['Feature']:<40} {row['Importance']:<12.6f} {cumulative_importance*100:<15.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ebb4c6",
   "metadata": {},
   "source": [
    "### 5.2 Visualize Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c41f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 20 features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "fig.suptitle('Feature Importance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Top 20 features bar chart\n",
    "top_n = 20\n",
    "top_features = feature_importances.head(top_n)\n",
    "\n",
    "colors = plt.cm.RdYlGn(top_features['Importance'] / top_features['Importance'].max())\n",
    "bars = axes[0].barh(range(len(top_features)), top_features['Importance'], color=colors, edgecolor='black')\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['Feature'], fontsize=10)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title(f'Top {top_n} Most Important Features', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (idx, row) in enumerate(top_features.iterrows()):\n",
    "    axes[0].text(row['Importance'] + 0.001, i, f\"{row['Importance']:.4f}\", \n",
    "                va='center', fontsize=9)\n",
    "\n",
    "# Plot 2: Cumulative importance\n",
    "cumsum = feature_importances['Importance'].cumsum()\n",
    "axes[1].plot(range(1, len(cumsum)+1), cumsum * 100, marker='o', linewidth=2, markersize=4)\n",
    "axes[1].axhline(y=80, color='r', linestyle='--', linewidth=2, label='80% threshold')\n",
    "axes[1].axhline(y=90, color='orange', linestyle='--', linewidth=2, label='90% threshold')\n",
    "axes[1].axhline(y=95, color='green', linestyle='--', linewidth=2, label='95% threshold')\n",
    "axes[1].set_xlabel('Number of Features', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Cumulative Importance (%)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Cumulative Feature Importance', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find how many features needed for different thresholds\n",
    "for threshold in [0.80, 0.90, 0.95]:\n",
    "    n_features = (cumsum <= threshold).sum() + 1\n",
    "    print(f\"Features needed for {threshold*100:.0f}% importance: {n_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c36d2",
   "metadata": {},
   "source": [
    "### 5.3 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlation among top features\n",
    "print(\"=\"*80)\n",
    "print(\"CORRELATION ANALYSIS (Multicollinearity Check)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select top 15 features for correlation analysis\n",
    "top_15_features = feature_importances.head(15)['Feature'].tolist()\n",
    "X_top_15 = X_train_val_encoded[top_15_features]\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = X_top_15.corr()\n",
    "\n",
    "# Visualize correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix: Top 15 Important Features', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Helper function to check if two features are from same One-Hot group\n",
    "def is_same_onehot_group(feat1, feat2):\n",
    "    \"\"\"Check if two features belong to the same One-Hot encoded group\"\"\"\n",
    "    onehot_prefixes = ['company_type_', 'gender_', 'major_', 'enrolled_']\n",
    "    for prefix in onehot_prefixes:\n",
    "        if feat1.startswith(prefix) and feat2.startswith(prefix):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Find highly correlated pairs (excluding within-group One-Hot correlations)\n",
    "print(\"\\nHighly Correlated Feature Pairs (|correlation| > 0.7):\")\n",
    "print(\"Note: Excluding correlations within same One-Hot encoded groups\")\n",
    "print(\"      (e.g., major_STEM vs major_Unknown is expected to be correlated)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "all_high_corr = []\n",
    "meaningful_high_corr = []\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        feat1 = correlation_matrix.columns[i]\n",
    "        feat2 = correlation_matrix.columns[j]\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        \n",
    "        if abs(corr_value) > 0.7:\n",
    "            all_high_corr.append((feat1, feat2, corr_value))\n",
    "            \n",
    "            # Only report if not from same One-Hot group\n",
    "            if not is_same_onehot_group(feat1, feat2):\n",
    "                meaningful_high_corr.append((feat1, feat2, corr_value))\n",
    "                print(f\"  {feat1:<35} <-> {feat2:<35} : {corr_value:>6.3f}\")\n",
    "\n",
    "if len(meaningful_high_corr) == 0:\n",
    "    print(\"  No highly correlated pairs found (good - low multicollinearity)\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(meaningful_high_corr)} meaningful high-correlation pairs\")\n",
    "\n",
    "# Report excluded One-Hot correlations\n",
    "onehot_excluded = len(all_high_corr) - len(meaningful_high_corr)\n",
    "if onehot_excluded > 0:\n",
    "    print(f\"\\nNote: Excluded {onehot_excluded} within-group One-Hot correlations\")\n",
    "    print(\"      (These are expected and don't indicate redundancy)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Analyze meaningful correlations in detail\n",
    "if len(meaningful_high_corr) > 0:\n",
    "    print(\"\\nDETAILED ANALYSIS OF MEANINGFUL CORRELATIONS:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for feat1, feat2, corr in meaningful_high_corr:\n",
    "        print(f\"\\n{feat1} <-> {feat2} (r = {corr:.3f})\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Special analysis for specific pairs\n",
    "        if 'city_encoded' in feat1 or 'city_encoded' in feat2:\n",
    "            if 'city_development_index' in feat1 or 'city_development_index' in feat2:\n",
    "                print(\"Interpretation:\")\n",
    "                print(\"  - city_encoded: Target encoding based on job change rate by city\")\n",
    "                print(\"  - city_development_index: Objective measure of city development\")\n",
    "                print(\"  - Negative correlation suggests: Less developed cities have higher job change rates\")\n",
    "                print(\"Decision: Keep both (capture different aspects despite correlation)\")\n",
    "        \n",
    "        if 'company_size_missing' in feat1 or 'company_size_missing' in feat2:\n",
    "            if 'company_type_Unknown' in feat1 or 'company_type_Unknown' in feat2:\n",
    "                print(\"Interpretation:\")\n",
    "                print(\"  - Both features indicate missing/unknown company information\")\n",
    "                print(\"  - High correlation reflects data quality patterns\")\n",
    "                print(\"  - Candidates who skip one field often skip related fields\")\n",
    "                print(\"Decision: Keep both (missing pattern itself may be predictive)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc56a6",
   "metadata": {},
   "source": [
    "### 5.4 Feature Selection Experiment\n",
    "\n",
    "**Experiment Design:**\n",
    "\n",
    "We will compare model performance using:\n",
    "1. **All features** (baseline)\n",
    "2. **Top 15 features** (80%+ cumulative importance)\n",
    "3. **Top 10 features** (aggressive selection)\n",
    "\n",
    "**Evaluation Method:**\n",
    "- 5-Fold Stratified Cross-Validation\n",
    "- Metric: F1-Score (primary, due to class imbalance) + Accuracy\n",
    "- Model: Random Forest (consistent with importance analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE SELECTION EXPERIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define feature sets to test\n",
    "feature_sets = {\n",
    "    'All Features': X_train_val_encoded.columns.tolist(),\n",
    "    'Top 15 Features': feature_importances.head(15)['Feature'].tolist(),\n",
    "    'Top 10 Features': feature_importances.head(10)['Feature'].tolist(),\n",
    "    'Top 8 Features': feature_importances.head(8)['Feature'].tolist()\n",
    "}\n",
    "\n",
    "# Setup cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=22207256)\n",
    "\n",
    "# Test each feature set\n",
    "results = []\n",
    "\n",
    "for name, features in feature_sets.items():\n",
    "    print(f\"\\nTesting: {name} ({len(features)} features)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Prepare data\n",
    "    X_subset = X_train_val_encoded[features]\n",
    "    \n",
    "    # Train model with cross-validation\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=22207256, n_jobs=-1)\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        rf, X_subset, y_train_val,\n",
    "        cv=skf,\n",
    "        scoring=['f1', 'accuracy', 'precision', 'recall'],\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    # Calculate mean scores\n",
    "    f1_mean = cv_results['test_f1'].mean()\n",
    "    f1_std = cv_results['test_f1'].std()\n",
    "    acc_mean = cv_results['test_accuracy'].mean()\n",
    "    acc_std = cv_results['test_accuracy'].std()\n",
    "    prec_mean = cv_results['test_precision'].mean()\n",
    "    rec_mean = cv_results['test_recall'].mean()\n",
    "    \n",
    "    results.append({\n",
    "        'Feature Set': name,\n",
    "        'N Features': len(features),\n",
    "        'F1-Score': f1_mean,\n",
    "        'F1 Std': f1_std,\n",
    "        'Accuracy': acc_mean,\n",
    "        'Acc Std': acc_std,\n",
    "        'Precision': prec_mean,\n",
    "        'Recall': rec_mean\n",
    "    })\n",
    "    \n",
    "    print(f\"   F1-Score:  {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
    "    print(f\"   Accuracy:  {acc_mean:.4f} Â± {acc_std:.4f}\")\n",
    "    print(f\"   Precision: {prec_mean:.4f}\")\n",
    "    print(f\"   Recall:    {rec_mean:.4f}\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Highlight best performance for each metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST PERFORMANCE BY METRIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_to_check = ['F1-Score', 'Accuracy', 'Precision', 'Recall']\n",
    "print(f\"\\n{'Metric':<15} {'Best Value':<15} {'Feature Set':<20} {'N Features':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for metric in metrics_to_check:\n",
    "    best_idx = results_df[metric].idxmax()\n",
    "    best_value = results_df.loc[best_idx, metric]\n",
    "    best_set = results_df.loc[best_idx, 'Feature Set']\n",
    "    n_features = results_df.loc[best_idx, 'N Features']\n",
    "    print(f\"{metric:<15} {best_value:<15.4f} {best_set:<20} {n_features:<12}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRIC EXPLANATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "ðŸ“Š **F1-Score** (Primary Metric) â­\n",
    "   - Harmonic mean of Precision and Recall\n",
    "   - Best for imbalanced data (your data is 3.75:1)\n",
    "   - Formula: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)\n",
    "   - Range: 0-1 (higher is better)\n",
    "   - âœ… Use this as primary evaluation metric\n",
    "\n",
    "ðŸ“ˆ **Accuracy**\n",
    "   - Overall correctness: (TP + TN) / Total\n",
    "   - Range: 0-1 (higher is better)\n",
    "   - âš ï¸ Can be misleading with imbalanced data\n",
    "   - Example: Predicting all \"0\" gives 75% accuracy!\n",
    "\n",
    "ðŸŽ¯ **Precision** (æŸ¥å‡†çŽ‡)\n",
    "   - \"How many predicted job changers actually changed?\"\n",
    "   - Formula: TP / (TP + FP)\n",
    "   - Important when: Cost of false positives is high\n",
    "   - Business case: Avoid wasting resources on non-changers\n",
    "\n",
    "ðŸ” **Recall** (æŸ¥å…¨çŽ‡)\n",
    "   - \"How many actual job changers did we find?\"\n",
    "   - Formula: TP / (TP + FN)\n",
    "   - Important when: Cost of missing positives is high\n",
    "   - Business case: Don't miss employees who want to leave\n",
    "\n",
    "ðŸ’¡ **Trade-off**: High Precision â†”ï¸ High Recall (can't maximize both)\n",
    "   F1-Score balances this trade-off automatically\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeade39",
   "metadata": {},
   "source": [
    "### 5.5 Visualize Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e8eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison with enhanced annotations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig.suptitle('Feature Selection Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: F1-Score comparison (Top-Left)\n",
    "x_pos = np.arange(len(results_df))\n",
    "colors_f1 = ['#2ecc71' if i == results_df['F1-Score'].idxmax() else '#3498db' \n",
    "             for i in range(len(results_df))]\n",
    "bars = axes[0, 0].bar(x_pos, results_df['F1-Score'], \n",
    "                       yerr=results_df['F1 Std'], \n",
    "                       capsize=5, alpha=0.8, \n",
    "                       color=colors_f1,\n",
    "                       edgecolor='black', linewidth=1.5)\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(results_df['Feature Set'], rotation=15, ha='right')\n",
    "axes[0, 0].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('F1-Score by Feature Set (â­ Primary Metric)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Mark best performance\n",
    "best_f1_idx = results_df['F1-Score'].idxmax()\n",
    "axes[0, 0].axhline(y=results_df.loc[best_f1_idx, 'F1-Score'], \n",
    "                    color='red', linestyle='--', linewidth=2, alpha=0.5, label='Best Performance')\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, row) in enumerate(zip(bars, results_df.iterrows())):\n",
    "    height = bar.get_height()\n",
    "    label = f'{row[1][\"F1-Score\"]:.4f}'\n",
    "    if i == best_f1_idx:\n",
    "        label += ' â­'\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                     label, ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Plot 2: Accuracy comparison (Top-Right)\n",
    "colors_acc = ['#2ecc71' if i == results_df['Accuracy'].idxmax() else '#e74c3c' \n",
    "              for i in range(len(results_df))]\n",
    "bars = axes[0, 1].bar(x_pos, results_df['Accuracy'], \n",
    "                       yerr=results_df['Acc Std'], \n",
    "                       capsize=5, alpha=0.8, \n",
    "                       color=colors_acc,\n",
    "                       edgecolor='black', linewidth=1.5)\n",
    "axes[0, 1].set_xticks(x_pos)\n",
    "axes[0, 1].set_xticklabels(results_df['Feature Set'], rotation=15, ha='right')\n",
    "axes[0, 1].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Accuracy by Feature Set', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "best_acc_idx = results_df['Accuracy'].idxmax()\n",
    "axes[0, 1].axhline(y=results_df.loc[best_acc_idx, 'Accuracy'], \n",
    "                    color='red', linestyle='--', linewidth=2, alpha=0.5, label='Best Performance')\n",
    "\n",
    "for i, (bar, row) in enumerate(zip(bars, results_df.iterrows())):\n",
    "    height = bar.get_height()\n",
    "    label = f'{row[1][\"Accuracy\"]:.4f}'\n",
    "    if i == best_acc_idx:\n",
    "        label += ' â­'\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                     label, ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Plot 3: Precision comparison (Bottom-Left)\n",
    "colors_prec = ['#2ecc71' if i == results_df['Precision'].idxmax() else '#f39c12' \n",
    "               for i in range(len(results_df))]\n",
    "bars = axes[1, 0].bar(x_pos, results_df['Precision'], \n",
    "                       alpha=0.8, \n",
    "                       color=colors_prec,\n",
    "                       edgecolor='black', linewidth=1.5)\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(results_df['Feature Set'], rotation=15, ha='right')\n",
    "axes[1, 0].set_ylabel('Precision (æŸ¥å‡†çŽ‡)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('Precision: \"How reliable are positive predictions?\"', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "best_prec_idx = results_df['Precision'].idxmax()\n",
    "axes[1, 0].axhline(y=results_df.loc[best_prec_idx, 'Precision'], \n",
    "                    color='red', linestyle='--', linewidth=2, alpha=0.5, label='Best Performance')\n",
    "\n",
    "for i, (bar, row) in enumerate(zip(bars, results_df.iterrows())):\n",
    "    height = bar.get_height()\n",
    "    label = f'{row[1][\"Precision\"]:.4f}'\n",
    "    if i == best_prec_idx:\n",
    "        label += ' â­'\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                     label, ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Plot 4: Recall comparison (Bottom-Right)\n",
    "colors_rec = ['#2ecc71' if i == results_df['Recall'].idxmax() else '#9b59b6' \n",
    "              for i in range(len(results_df))]\n",
    "bars = axes[1, 1].bar(x_pos, results_df['Recall'], \n",
    "                       alpha=0.8, \n",
    "                       color=colors_rec,\n",
    "                       edgecolor='black', linewidth=1.5)\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(results_df['Feature Set'], rotation=15, ha='right')\n",
    "axes[1, 1].set_ylabel('Recall (æŸ¥å…¨çŽ‡)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('Recall: \"How many actual positives did we find?\"', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "best_rec_idx = results_df['Recall'].idxmax()\n",
    "axes[1, 1].axhline(y=results_df.loc[best_rec_idx, 'Recall'], \n",
    "                    color='red', linestyle='--', linewidth=2, alpha=0.5, label='Best Performance')\n",
    "\n",
    "for i, (bar, row) in enumerate(zip(bars, results_df.iterrows())):\n",
    "    height = bar.get_height()\n",
    "    label = f'{row[1][\"Recall\"]:.4f}'\n",
    "    if i == best_rec_idx:\n",
    "        label += ' â­'\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                     label, ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of best performers\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nðŸ¥‡ Best F1-Score:  {results_df.loc[best_f1_idx, 'Feature Set']:<20} = {results_df.loc[best_f1_idx, 'F1-Score']:.4f}\")\n",
    "print(f\"ðŸ¥‡ Best Accuracy:  {results_df.loc[best_acc_idx, 'Feature Set']:<20} = {results_df.loc[best_acc_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"ðŸ¥‡ Best Precision: {results_df.loc[best_prec_idx, 'Feature Set']:<20} = {results_df.loc[best_prec_idx, 'Precision']:.4f}\")\n",
    "print(f\"ðŸ¥‡ Best Recall:    {results_df.loc[best_rec_idx, 'Feature Set']:<20} = {results_df.loc[best_rec_idx, 'Recall']:.4f}\")\n",
    "\n",
    "# Check if same model wins all metrics\n",
    "all_same = (best_f1_idx == best_acc_idx == best_prec_idx == best_rec_idx)\n",
    "if all_same:\n",
    "    print(f\"\\nâœ… Winner: {results_df.loc[best_f1_idx, 'Feature Set']} dominates ALL metrics!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ Different models perform best on different metrics\")\n",
    "    print(f\"   â†’ Recommendation: Use F1-Score as primary metric (balances Precision & Recall)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47670f56",
   "metadata": {},
   "source": [
    "### 5.6 Final Feature Selection Decision\n",
    "\n",
    "**Analysis of Results:**\n",
    "\n",
    "Based on the experiments above, we analyze:\n",
    "\n",
    "1. **Performance vs Complexity Trade-off**\n",
    "   - All features provide baseline performance but highest complexity\n",
    "   - Top 15 features capture 80%+ importance with minimal performance loss\n",
    "   - Top 10 features balance simplicity and performance\n",
    "   - Top 8 features may sacrifice too much performance\n",
    "\n",
    "2. **F1-Score Priority**\n",
    "   - Given class imbalance (3.75:1), F1-Score is our primary metric\n",
    "   - We prioritize F1-Score > Accuracy\n",
    "\n",
    "3. **Multicollinearity Check**\n",
    "   - Low correlation among top features (checked in Section 5.3)\n",
    "   - No need to remove redundant features\n",
    "\n",
    "**Decision Criteria:**\n",
    "- If F1-Score difference < 0.01: Choose simpler model (fewer features)\n",
    "- If F1-Score difference â‰¥ 0.01: Choose more complex model (more features)\n",
    "- Consider interpretability and computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make final decision based on results\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: ANALYZE EXPERIMENT RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define One-Hot encoded feature groups\n",
    "onehot_groups = {\n",
    "    'major_discipline': ['major_STEM', 'major_Business Degree', 'major_Arts', \n",
    "                        'major_Humanities', 'major_No Major', 'major_Unknown', 'major_Other'],\n",
    "    'company_type': ['company_type_Early Stage Startup', 'company_type_Funded Startup',\n",
    "                    'company_type_NGO', 'company_type_Other', \n",
    "                    'company_type_Public Sector', 'company_type_Pvt Ltd',\n",
    "                    'company_type_Unknown'],\n",
    "    'gender': ['gender_Female', 'gender_Male', 'gender_Other', 'gender_Unknown'],\n",
    "    'enrolled_university': ['enrolled_Full time course', 'enrolled_Part time course',\n",
    "                           'enrolled_no_enrollment']\n",
    "}\n",
    "\n",
    "# Get baseline performance (All Features)\n",
    "baseline_f1 = results_df.loc[0, 'F1-Score']\n",
    "baseline_features = results_df.loc[0, 'N Features']\n",
    "\n",
    "print(f\"\\nBaseline (All Features):\")\n",
    "print(f\"   Features: {baseline_features}\")\n",
    "print(f\"   F1-Score: {baseline_f1:.4f}\")\n",
    "\n",
    "# Analyze performance differences\n",
    "print(f\"\\n{'Feature Set':<20} {'N Features':<12} {'F1-Score':<12} {'Diff from Baseline':<20} {'Feature Reduction':<18}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "candidates = []  # Store candidates that meet threshold\n",
    "for idx, row in results_df.iterrows():\n",
    "    f1_diff = baseline_f1 - row['F1-Score']\n",
    "    feature_reduction = (1 - row['N Features'] / baseline_features) * 100\n",
    "    \n",
    "    print(f\"{row['Feature Set']:<20} {row['N Features']:<12} {row['F1-Score']:<12.4f} {f1_diff:+.4f} ({abs(f1_diff)/baseline_f1*100:.2f}%)  {feature_reduction:>6.1f}%\")\n",
    "    \n",
    "    # Mark candidates with acceptable performance loss (< 1% or < 0.01 absolute)\n",
    "    if abs(f1_diff) < 0.01:\n",
    "        candidates.append({\n",
    "            'name': row['Feature Set'],\n",
    "            'n_features': row['N Features'],\n",
    "            'f1': row['F1-Score'],\n",
    "            'diff': f1_diff\n",
    "        })\n",
    "\n",
    "# Decision logic: Prioritize performance improvement, then simplicity\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: DECISION CRITERIA\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThreshold: F1-Score difference < 0.01 (1% relative difference)\")\n",
    "print(f\"\\nCandidates meeting threshold:\")\n",
    "\n",
    "# Separate candidates into two groups\n",
    "better_than_baseline = []  # F1 > baseline (diff < 0)\n",
    "acceptable_candidates = []  # F1 â‰ˆ baseline (small diff)\n",
    "\n",
    "if len(candidates) > 0:\n",
    "    for c in candidates:\n",
    "        marker = \"\"\n",
    "        if c['diff'] < 0:  # Better than baseline\n",
    "            better_than_baseline.append(c)\n",
    "            marker = \" ðŸŒŸ BETTER than baseline!\"\n",
    "        else:\n",
    "            acceptable_candidates.append(c)\n",
    "        print(f\"   âœ“ {c['name']:<20} ({c['n_features']} features, F1={c['f1']:.4f}, Î”={c['diff']:+.4f}){marker}\")\n",
    "    \n",
    "    # Decision logic\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"DECISION LOGIC\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if len(better_than_baseline) > 0:\n",
    "        # Rule 1: If any model is BETTER than baseline, choose the best one\n",
    "        print(\"\\nâœ“ Found model(s) BETTER than baseline!\")\n",
    "        print(\"  Rule: Choose the model with HIGHEST F1-Score\")\n",
    "        \n",
    "        best_candidate = max(better_than_baseline, key=lambda x: x['f1'])\n",
    "        selected_feature_set = best_candidate['name']\n",
    "        \n",
    "        print(f\"\\n  â†’ Selected: {selected_feature_set}\")\n",
    "        print(f\"     Reason: Best F1-Score ({best_candidate['f1']:.4f})\")\n",
    "        print(f\"     Benefit: +{abs(best_candidate['diff']):.4f} improvement over baseline\")\n",
    "        print(f\"     Cost: {(1 - best_candidate['n_features']/baseline_features)*100:.1f}% feature reduction\")\n",
    "    else:\n",
    "        # Rule 2: If no improvement, choose simplest acceptable model\n",
    "        print(\"\\nâ—‹ No model improves over baseline\")\n",
    "        print(\"  Rule: Choose the SIMPLEST model (fewest features) with acceptable performance\")\n",
    "        \n",
    "        best_candidate = min(candidates, key=lambda x: x['n_features'])\n",
    "        selected_feature_set = best_candidate['name']\n",
    "        \n",
    "        print(f\"\\n  â†’ Selected: {selected_feature_set}\")\n",
    "        print(f\"     Reason: Fewest features ({best_candidate['n_features']}) with acceptable performance\")\n",
    "        print(f\"     Trade-off: {abs(best_candidate['diff']):.4f} F1-Score loss\")\n",
    "        print(f\"     Benefit: {(1 - best_candidate['n_features']/baseline_features)*100:.1f}% feature reduction\")\n",
    "else:\n",
    "    print(f\"   âœ— No candidates meet threshold\")\n",
    "    print(f\"   â†’ Using All Features for maximum performance\")\n",
    "    selected_feature_set = 'All Features'\n",
    "\n",
    "# Get the initial feature list based on selection\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: INITIAL FEATURE SELECTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSelected: {selected_feature_set}\")\n",
    "\n",
    "if selected_feature_set == 'All Features':\n",
    "    initial_features = X_train_val_encoded.columns.tolist()\n",
    "    print(f\"   Using all {len(initial_features)} features\")\n",
    "elif selected_feature_set == 'Top 15 Features':\n",
    "    initial_features = feature_importances.head(15)['Feature'].tolist()\n",
    "    print(f\"   Using top 15 features by importance\")\n",
    "elif selected_feature_set == 'Top 10 Features':\n",
    "    initial_features = feature_importances.head(10)['Feature'].tolist()\n",
    "    print(f\"   Using top 10 features by importance\")\n",
    "elif selected_feature_set == 'Top 8 Features':\n",
    "    initial_features = feature_importances.head(8)['Feature'].tolist()\n",
    "    print(f\"   Using top 8 features by importance\")\n",
    "else:\n",
    "    initial_features = X_train_val_encoded.columns.tolist()\n",
    "    print(f\"   Default: Using all {len(initial_features)} features\")\n",
    "\n",
    "# Apply One-Hot group integrity check\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: ONE-HOT ENCODING GROUP INTEGRITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâš ï¸  IMPORTANT: One-Hot encoded groups must be kept complete!\")\n",
    "print(\"\\nReason:\")\n",
    "print(\"  - One-Hot columns are mutually exclusive representations of ONE categorical variable\")\n",
    "print(\"  - Keeping only partial columns would LOSE information about missing categories\")\n",
    "print(\"  - Example: If we keep only 'major_STEM', we cannot distinguish between\")\n",
    "print(\"            'Business', 'Arts', 'Humanities', 'No Major', and 'Unknown'\")\n",
    "print(\"\\nRule: If ANY column from a One-Hot group is selected, include the ENTIRE group.\")\n",
    "\n",
    "selected_features = []\n",
    "included_groups = set()\n",
    "added_features = []  # Track features added during group completion\n",
    "\n",
    "for feature in initial_features:\n",
    "    # Check if feature belongs to a One-Hot group\n",
    "    found_group = False\n",
    "    for group_name, group_cols in onehot_groups.items():\n",
    "        if feature in group_cols:\n",
    "            # Add entire group if not already added\n",
    "            if group_name not in included_groups:\n",
    "                print(f\"\\nâœ“ Found '{feature}' in group '{group_name}'\")\n",
    "                print(f\"  â†’ Adding complete group ({len(group_cols)} features)\")\n",
    "                # Track which features were not in initial selection\n",
    "                for col in group_cols:\n",
    "                    if col not in initial_features:\n",
    "                        added_features.append(col)\n",
    "                selected_features.extend(group_cols)\n",
    "                included_groups.add(group_name)\n",
    "            found_group = True\n",
    "            break\n",
    "    \n",
    "    # If not in any group, add directly\n",
    "    if not found_group:\n",
    "        selected_features.append(feature)\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "selected_features = list(dict.fromkeys(selected_features))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"GROUP COMPLETION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Initial selection: {len(initial_features)} features\")\n",
    "print(f\"After group completion: {len(selected_features)} features\")\n",
    "print(f\"Features added: +{len(selected_features) - len(initial_features)}\")\n",
    "\n",
    "if len(added_features) > 0:\n",
    "    print(f\"\\nâš ï¸  WARNING: {len(added_features)} features were added to complete One-Hot groups:\")\n",
    "    for feat in added_features:\n",
    "        print(f\"     + {feat}\")\n",
    "    print(f\"\\n   â†’ This changes the feature set from the experiment!\")\n",
    "    print(f\"   â†’ Need to re-validate performance with the completed feature set\")\n",
    "else:\n",
    "    print(f\"\\nâœ“ No additional features needed (all One-Hot groups are already complete)\")\n",
    "\n",
    "# STEP 5: Re-validate performance if features were added\n",
    "if len(added_features) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"STEP 5: RE-VALIDATE PERFORMANCE (WITH COMPLETED ONE-HOT GROUPS)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nRe-testing with {len(selected_features)} features (after One-Hot group completion)\")\n",
    "    \n",
    "    # Prepare data with completed feature set\n",
    "    X_subset_completed = X_train_val_encoded[selected_features]\n",
    "    \n",
    "    # Train model with cross-validation\n",
    "    rf_revalidate = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=22207256, n_jobs=-1)\n",
    "    skf_revalidate = StratifiedKFold(n_splits=5, shuffle=True, random_state=22207256)\n",
    "    \n",
    "    cv_results_completed = cross_validate(\n",
    "        rf_revalidate, X_subset_completed, y_train_val,\n",
    "        cv=skf_revalidate,\n",
    "        scoring=['f1', 'accuracy', 'precision', 'recall'],\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    # Calculate scores\n",
    "    completed_f1 = cv_results_completed['test_f1'].mean()\n",
    "    completed_f1_std = cv_results_completed['test_f1'].std()\n",
    "    completed_acc = cv_results_completed['test_accuracy'].mean()\n",
    "    completed_prec = cv_results_completed['test_precision'].mean()\n",
    "    completed_rec = cv_results_completed['test_recall'].mean()\n",
    "    \n",
    "    print(f\"\\nPerformance with {len(selected_features)} features (after completion):\")\n",
    "    print(f\"   F1-Score:  {completed_f1:.4f} Â± {completed_f1_std:.4f}\")\n",
    "    print(f\"   Accuracy:  {completed_acc:.4f}\")\n",
    "    print(f\"   Precision: {completed_prec:.4f}\")\n",
    "    print(f\"   Recall:    {completed_rec:.4f}\")\n",
    "    \n",
    "    # Compare with original selection\n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"   Original '{selected_feature_set}': F1 = {results_df[results_df['Feature Set']==selected_feature_set]['F1-Score'].values[0]:.4f} ({len(initial_features)} features)\")\n",
    "    print(f\"   After completion: F1 = {completed_f1:.4f} ({len(selected_features)} features)\")\n",
    "    print(f\"   Baseline (All Features): F1 = {baseline_f1:.4f} ({baseline_features} features)\")\n",
    "    \n",
    "    f1_diff_from_baseline = baseline_f1 - completed_f1\n",
    "    print(f\"\\n   Difference from baseline: {f1_diff_from_baseline:+.4f} ({abs(f1_diff_from_baseline)/baseline_f1*100:.2f}%)\")\n",
    "    \n",
    "    if abs(f1_diff_from_baseline) < 0.01:\n",
    "        print(f\"   âœ“ Still within acceptable threshold (<0.01)\")\n",
    "        print(f\"   âœ“ Decision confirmed: Use {len(selected_features)} selected features\")\n",
    "        final_decision = 'confirmed'\n",
    "    else:\n",
    "        print(f\"   âœ— Performance degraded beyond threshold\")\n",
    "        print(f\"   â†’ Recommendation: Consider using All Features instead\")\n",
    "        final_decision = 'consider_all_features'\n",
    "else:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"STEP 5: VALIDATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"âœ“ No features were added during One-Hot completion\")\n",
    "    print(f\"âœ“ Selected feature set matches the tested set in experiments\")\n",
    "    print(f\"âœ“ Performance already validated: F1 = {results_df[results_df['Feature Set']==selected_feature_set]['F1-Score'].values[0]:.4f}\")\n",
    "    final_decision = 'confirmed'\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FINAL FEATURE SET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Features selected: {len(selected_features)}\")\n",
    "print(f\"Decision status: {final_decision}\")\n",
    "\n",
    "# Calculate removed features\n",
    "all_original_features = X_train_val_encoded.columns.tolist()\n",
    "removed_features = [f for f in all_original_features if f not in selected_features]\n",
    "\n",
    "print(\"\\nOne-Hot groups included:\")\n",
    "for group_name in included_groups:\n",
    "    print(f\"  - {group_name} ({len(onehot_groups[group_name])} features)\")\n",
    "\n",
    "print(f\"\\nAll selected features ({len(selected_features)} total):\")\n",
    "for i, feat in enumerate(selected_features, 1):\n",
    "    if feat in feature_importances['Feature'].values:\n",
    "        importance = feature_importances[feature_importances['Feature'] == feat]['Importance'].values[0]\n",
    "        # Mark if it's part of a One-Hot group\n",
    "        in_group = any(feat in group_cols for group_cols in onehot_groups.values())\n",
    "        group_marker = \" [One-Hot]\" if in_group else \"\"\n",
    "        # Mark if it was added during completion\n",
    "        added_marker = \" [+Added]\" if feat in added_features else \"\"\n",
    "        print(f\"   {i:2d}. {feat:<45} (importance: {importance:.6f}){group_marker}{added_marker}\")\n",
    "    else:\n",
    "        # Feature not in top features (added during completion)\n",
    "        in_group = any(feat in group_cols for group_cols in onehot_groups.values())\n",
    "        group_marker = \" [One-Hot]\" if in_group else \"\"\n",
    "        print(f\"   {i:2d}. {feat:<45} (not in top features) [+Added]{group_marker}\")\n",
    "\n",
    "# Show removed features\n",
    "if len(removed_features) > 0:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"REMOVED FEATURES ({len(removed_features)} total)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"The following features were NOT selected:\")\n",
    "    \n",
    "    for i, feat in enumerate(removed_features, 1):\n",
    "        if feat in feature_importances['Feature'].values:\n",
    "            importance = feature_importances[feature_importances['Feature'] == feat]['Importance'].values[0]\n",
    "            # Mark if it's part of a One-Hot group\n",
    "            in_group = any(feat in group_cols for group_cols in onehot_groups.values())\n",
    "            group_marker = \" [One-Hot]\" if in_group else \"\"\n",
    "            print(f\"   {i:2d}. {feat:<45} (importance: {importance:.6f}){group_marker} [-Removed]\")\n",
    "        else:\n",
    "            # Feature not in importance ranking (very low importance)\n",
    "            in_group = any(feat in group_cols for group_cols in onehot_groups.values())\n",
    "            group_marker = \" [One-Hot]\" if in_group else \"\"\n",
    "            print(f\"   {i:2d}. {feat:<45} (not ranked) {group_marker} [-Removed]\")\n",
    "    \n",
    "    print(f\"\\nNote: These {len(removed_features)} features have low importance and were excluded to simplify the model.\")\n",
    "else:\n",
    "    print(f\"\\nNo features were removed (using all features)\")\n",
    "\n",
    "# Create final feature sets for modeling\n",
    "X_train_val_selected = X_train_val_encoded[selected_features]\n",
    "X_test_selected = X_test_encoded[selected_features]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… FEATURE SELECTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train+Val set: {X_train_val_selected.shape}\")\n",
    "print(f\"Test set:      {X_test_selected.shape}\")\n",
    "print(f\"\\nKey Points:\")\n",
    "print(f\"  1. All One-Hot encoded groups are kept intact (preserve categorical information)\")\n",
    "print(f\"  2. Performance has been {'validated' if len(added_features) > 0 else 'pre-validated'} with cross-validation\")\n",
    "print(f\"  3. Ready for final model training!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
